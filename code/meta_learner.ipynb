{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import importlib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "\n",
    "# Pycox and PyTorch tuples for survival analysis\n",
    "import torchtuples as tt\n",
    "import pycox\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "from pycox.models import CoxPH, DeepHit\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "# Ray for hyperparameter tuning and distributed processing\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.air import session\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "# Custom modules for data handling, balancing, training, evaluation, and model architectures\n",
    "import dataloader2\n",
    "import databalancer2\n",
    "import datatrainer2\n",
    "import modeleval\n",
    "import netweaver2\n",
    "\n",
    "# Reload custom modules to ensure latest changes are available\n",
    "importlib.reload(dataloader2)\n",
    "importlib.reload(databalancer2)\n",
    "importlib.reload(datatrainer2)\n",
    "importlib.reload(modeleval)\n",
    "importlib.reload(netweaver2)\n",
    "\n",
    "# Import specific functions from custom modules to keep code clean and readable\n",
    "from netweaver2 import (\n",
    "    lstm_net_init, DHANNWrapper, LSTMWrapper, generalized_ann_net_init\n",
    ")\n",
    "from dataloader2 import (\n",
    "    load_and_transform_data, preprocess_data #stack_sequences, dh_dataset_loader\n",
    ")\n",
    "from databalancer2 import (\n",
    "    define_medoid_general, df_event_focus, rebalance_data, underbalance_data_general, medoid_cluster, \n",
    "    dh_rebalance_data\n",
    ")\n",
    "from datatrainer2 import (\n",
    "    recursive_clustering, prepare_training_data, \n",
    "    prepare_validation_data, lstm_training\n",
    ")\n",
    "from modeleval import (\n",
    "    dh_test_model, nam_dagostino_chi2, get_baseline_hazard_at_timepoints, combined_test_model\n",
    ")\n",
    "\n",
    "import psutil\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define constants, load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:14,040 - INFO - Transforming training data...\n",
      "2024-11-11 01:11:28,099 - INFO - Transforming test data...\n"
     ]
    }
   ],
   "source": [
    "# Define Constants and Load Datasets\n",
    "RANDOM_SEED = 12345\n",
    "N_SPLIT = 2\n",
    "FEATURE_COLS = ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "DURATION_COL = 'date_from_sub_60'\n",
    "EVENT_COL = 'endpoint'\n",
    "CLUSTER_COL = 'key'\n",
    "TIME_GRID = np.array([i * 365 for i in range(6)])\n",
    "\n",
    "# Define Feature Groups\n",
    "CAT_FEATURES = ['gender', 'dm', 'ht', 'sprint']\n",
    "LOG_FEATURES = ['a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "STANDARD_FEATURES = ['age', 'alb', 'ca', 'hb', 'hco3']\n",
    "PASSTHROUGH_FEATURES = ['key', 'date_from_sub_60', 'endpoint']\n",
    "\n",
    "# Load and Transform Data\n",
    "BASE_FILENAME = '/mnt/d/pydatascience/g3_regress/data/X/X_20240628'\n",
    "X_train_transformed, X_test_transformed = load_and_transform_data(\n",
    "    BASE_FILENAME, CAT_FEATURES, LOG_FEATURES, STANDARD_FEATURES, PASSTHROUGH_FEATURES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and save models\n",
    "- model naming: {deepsurv/deephit}\\_{nn}\\_{resample method}_{outcome}\n",
    "- for deepsurv model, only the result in time_grid will be retrieved so the result of deepsurv and deephit models are compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(config, num_risk = len(X_train_transformed[EVENT_COL].unique()) - 1, num_time_bins=len(TIME_GRID)):\n",
    "    \"\"\"\n",
    "    Function to create a neural network based on the given configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration dictionary containing model type, network type, and hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Created neural network model.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if config['model'] == 'deepsurv':\n",
    "        num_risk = None\n",
    "        num_time_bins=None\n",
    "    elif config['model'] == 'deephit':\n",
    "        num_risk = num_risk\n",
    "        num_time_bins = num_time_bins\n",
    "    # Create the Neural Network\n",
    "    if config['net'] == 'ann':\n",
    "        net = generalized_ann_net_init(\n",
    "            input_size=len(config['features']),\n",
    "            num_nodes=config[\"num_nodes\"],\n",
    "            batch_norm=config[\"batch_norm\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            output_size=1, # Default output size for DeepSurv\n",
    "            num_risks = num_risk,\n",
    "            num_time_bins = num_time_bins\n",
    "        )\n",
    "    elif config['net'] == 'lstm':\n",
    "        net = lstm_net_init(\n",
    "            input_size=len(config['features']),\n",
    "            num_nodes=config[\"num_nodes\"],\n",
    "            batch_norm=config[\"batch_norm\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            num_risks = num_risk,\n",
    "            num_time_bins = num_time_bins\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown network type: {}\".format(config['net']))\n",
    "\n",
    "    optimizer = tt.optim.AdamWR(decoupled_weight_decay=1e-6, cycle_eta_multiplier=0.8)\n",
    "    if config['model'] == 'deepsurv':\n",
    "        model = CoxPH(net, optimizer)\n",
    "    elif config['model'] == 'deephit':\n",
    "        model = DeepHit(net, optimizer)\n",
    "    model.optimizer.set_lr(config[\"lr\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_neural_network(model, config, X_train, X_val, duration_col, event_col, cluster_col, callbacks, time_grid=None):\n",
    "    \"\"\"\n",
    "    Function to train a given neural network using the provided datasets.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): Neural network to be trained.\n",
    "        config (dict): Configuration dictionary containing model hyperparameters.\n",
    "        X_train (pd.DataFrame): Training dataset with features.\n",
    "        X_val (pd.DataFrame): Validation dataset with features.\n",
    "        duration_col (str): Column representing event durations.\n",
    "        event_col (str): Column representing event occurrences.\n",
    "        cluster_col (str): Column for grouping during cross-validation.\n",
    "        callbacks (list): List of callbacks for training.\n",
    "        time_grid (np.array, optional): Time grid for evaluation if required. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        model: Trained PyCox model.\n",
    "        logs: Training logs.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # Train the model\n",
    "    if config['model'] == 'deepsurv':\n",
    "        print('Initiate training of deepsurv neural network')\n",
    "        X_val = df_event_focus(X_val, event_col, config['endpoint'])\n",
    "        X_val_processed, y_val = preprocess_data(X_val, config['features'], duration_col, event_col)\n",
    "        val_data = (X_val_processed, y_val)\n",
    "        if config['net'] == 'ann':\n",
    "            print('model structure: ANN')\n",
    "            if config['balance_method'] == 'clustering':\n",
    "                print('data balancing method: clustering')\n",
    "                model, logs = recursive_clustering(model, X_train, duration_col, event_col, config, val_data, callbacks, max_repeats=30)\n",
    "            elif config['balance_method'] == 'enn':\n",
    "                print('data balancing method: smoteenn')\n",
    "                X_train = rebalance_data(X_train, event_col, config['endpoint'], CAT_FEATURES, config, RANDOM_SEED, method='ENN')\n",
    "                X_train, y_train = preprocess_data(X_train, config['features'], duration_col, event_col)\n",
    "                logs = model.fit(X_train, y_train, config['batch_size'], int(config['max_epochs']), callbacks, verbose=True, val_data=val_data, num_workers=10)\n",
    "            elif config['balance_method'] == 'tomek':\n",
    "                print('data balancing method: smotetomek')\n",
    "                X_train = rebalance_data(X_train, event_col, config['endpoint'], CAT_FEATURES, config, RANDOM_SEED, method='Tomek')\n",
    "                X_train, y_train = preprocess_data(X_train, config['features'], duration_col, event_col)\n",
    "                logs = model.fit(X_train, y_train, config['batch_size'], int(config['max_epochs']), callbacks, verbose=True, val_data=val_data, num_workers=10)\n",
    "        elif config['net'] == 'lstm':\n",
    "            print('model structure: LSTM')\n",
    "            if config['balance_method'] == 'clustering':\n",
    "                print('data balancing method: clustering')\n",
    "                model, logs = lstm_training(model, X_train, X_val, duration_col, event_col, cluster_col, config, callbacks, time_grid)\n",
    "            elif config['balance_method'] == 'NearMiss':\n",
    "                print('data balancing method: NearMiss')\n",
    "                model, logs = lstm_training(model, X_train, X_val, duration_col, event_col, cluster_col, config, callbacks, time_grid)\n",
    "    elif config['model'] == 'deephit':\n",
    "        print('Initiate training of deephit neural network')\n",
    "        X_val_processed, y_val = preprocess_data(X_val, config['features'], duration_col, event_col, TIME_GRID, discretize=True)\n",
    "        val_data = (X_val_processed, y_val)\n",
    "        if config['net'] == 'ann':\n",
    "            print('model structure: ANN')\n",
    "            if config['balance_method'] == 'clustering':\n",
    "                print('data balancing method: clustering')\n",
    "                model, logs = recursive_clustering(model, X_train, duration_col, event_col, config, val_data, callbacks, max_repeats=30, time_grid=TIME_GRID)\n",
    "            elif config['balance_method'] == 'NearMiss':\n",
    "                print('data balancing method: NearMiss')\n",
    "                X_train = underbalance_data_general(X_train, EVENT_COL, CLUSTER_COL, config, version=config['version'])\n",
    "                X_train, y_train = preprocess_data(X_train, config['features'], duration_col, event_col, TIME_GRID, discretize=True)\n",
    "                logs = model.fit(X_train, y_train, config['batch_size'], int(config['max_epochs']), callbacks, verbose=True, val_data=val_data)\n",
    "        elif config['net'] == 'lstm':\n",
    "            print('model structure: LSTM')\n",
    "            if config['balance_method'] == 'clustering':\n",
    "                print('data balancing method: clustering')\n",
    "                model, logs = lstm_training(model, X_train, X_val, duration_col, event_col, cluster_col, config, callbacks, time_grid)\n",
    "            elif config['balance_method'] == 'NearMiss':\n",
    "                print('data balancing method: NearMiss')\n",
    "                model, logs = lstm_training(model, X_train, X_val, duration_col, event_col, cluster_col, config, callbacks, time_grid)        \n",
    "\n",
    "    # Free memory after training\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, logs\n",
    "\n",
    "def save_model(params, model, model_path, baseline_hazard_path):\n",
    "    \"\"\"\n",
    "    Save model weights and baseline hazard data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to save.\n",
    "    - model_path: Path to save the model weights (.pt file).\n",
    "    - baseline_hazard_path: Path to save the baseline hazards (.pkl file).\n",
    "    \"\"\"\n",
    "    # Compute baseline hazards and save\n",
    "    if params['model'] == 'deepsurv':\n",
    "        baseline_hazard = model.compute_baseline_hazards()\n",
    "        baseline_hazard.to_pickle(baseline_hazard_path)\n",
    "    \n",
    "    # Save model weights\n",
    "    model.save_model_weights(model_path)\n",
    "    print(f\"Model and baseline hazards saved to {model_path} and {baseline_hazard_path}.\")\n",
    "\n",
    "def training_wrapper(df, config, spliter, model_path, hazard_path, feature_col=FEATURE_COLS, duration_col=DURATION_COL, event_col=EVENT_COL, cluster_col=CLUSTER_COL, time_grid=TIME_GRID):\n",
    "    \"\"\"\n",
    "    Train and save a survival analysis model with grouped cross-validation splits.\n",
    "\n",
    "    This function performs training on grouped cross-validation splits of the input DataFrame and saves each trained model\n",
    "    along with its baseline hazards. Memory management is handled to ensure efficient GPU usage.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing training data.\n",
    "    - config (dict): Configuration dictionary for initializing the neural network.\n",
    "    - spliter (object): Splitter object (e.g., GroupShuffleSplit or StratifiedKFold) used for creating train-validation splits.\n",
    "    - model_path (str): File path to save the trained model weights (.pt file).\n",
    "    - hazard_path (str): File path to save the baseline hazards (.pkl file).\n",
    "    - feature_col (list): List of feature column names in `df` used for model training.\n",
    "    - duration_col (str): Name of the column representing duration/time-to-event.\n",
    "    - event_col (str): Name of the column representing the event indicator (0 = censored, 1 = event).\n",
    "    - cluster_col (str): Name of the column used for grouping (clusters for cross-validation).\n",
    "    - time_grid (list): List or array defining the time grid for training.\n",
    "\n",
    "    Returns:\n",
    "    - None: Saves the model weights and baseline hazard data for each cross-validation split.\n",
    "    \"\"\"\n",
    "    for train_idx, val_idx in spliter.split(X=df[feature_col], y=df[event_col], groups=df[cluster_col]):\n",
    "        # Clear GPU memory for each split\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Define early stopping callback\n",
    "        callbacks = [tt.cb.EarlyStopping()]\n",
    "        \n",
    "        # Create training and validation sets\n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "        \n",
    "        # Initialize and train the model\n",
    "        model = create_neural_network(config)\n",
    "        model, logs = train_neural_network(\n",
    "            model, config,\n",
    "            X_train=train_df, X_val=val_df,\n",
    "            duration_col=duration_col, event_col=event_col,\n",
    "            cluster_col=cluster_col, callbacks=callbacks, time_grid=time_grid\n",
    "        )\n",
    "        \n",
    "        # Save the trained model and its baseline hazards\n",
    "        save_model(config, model, model_path, hazard_path)\n",
    "        \n",
    "        # Free memory for the next iteration\n",
    "        del model, logs\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"Training and saving completed for all cross-validation splits.\")\n",
    "\n",
    "    print(\"All models have been trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 deepsurv_ann_clustering_1\n",
    "- features: ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "- sampling strategy: 0.05\n",
    "- 2 hidden layers with 8 and 4 nodes\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.1144793446270997\n",
    "- learning rate: 0.1\n",
    "- max epochs: 9\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "deepsurv_ann_clustering_1_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'clustering',\n",
    "    'features': ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [8, 4],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.1144793446270997,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 9,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 deepsurv_ann_smoteenn_1\n",
    "- features: ['ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'hb', 'hco3']\n",
    "- sampling strategy: 0.3\n",
    "- 4 hidden layers with 64, 32, 16 and 8 nodes\n",
    "- batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.09555033386059111\n",
    "- learning rate: 0.1\n",
    "- max epochs: 16\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_ann_smoteenn_1_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'enn',\n",
    "    'features': ['ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'hb', 'hco3'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [64, 32, 16, 8],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.09555033386059111,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 16,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.3,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 deepsurv_ann_smotetomek_1\n",
    "- features:  ['gender', 'dm', 'ht', 'sprint', 'po4', 'UACR_mg_g', 'Cr', 'age', 'hb', 'hco3']\n",
    "- sampling strategy: 0.2\n",
    "- 3 hidden layers with 32, 16 and 8 nodes\n",
    "- batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.23872991564684112\n",
    "- learning rate: 0.1\n",
    "- max epochs: 14\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_ann_smotetomek_1_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'tomek',\n",
    "    'features': ['gender', 'dm', 'ht', 'sprint', 'po4', 'UACR_mg_g', 'Cr', 'age', 'hb', 'hco3'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [32, 16, 8],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.23872991564684112,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 14,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.2,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 deepsurv_ann_clustering_2\n",
    "- features: [\"gender\", \"a1c\", \"po4\", \"UACR_mg_g\", \"Cr\"]\n",
    "- sampling_strategy: 0.05\n",
    "- 3 hidden layers with 32, 16, 8 nodes\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.3058921011568742\n",
    "- learning rate: 0.1\n",
    "- max epochs: 14\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_ann_clustering_2_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'clustering',\n",
    "    'features': [\"gender\", \"a1c\", \"po4\", \"UACR_mg_g\", \"Cr\"],\n",
    "    'endpoint': 2,\n",
    "    'num_nodes': [32, 16, 8],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.3058921011568742,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 14,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 deepsurv_ann_smoteenn_2\n",
    "- features: [\"gender\", \"dm\", \"ht\", \"sprint\", \"a1c\", \"po4\", \"UACR_mg_g\", \"Cr\", \"age\", \"alb\", \"ca\", \"hb\", \"hco3\"]\n",
    "- sampling_strategy: 0.1, \n",
    "- 2 hidden layers with 8, 4 nodes\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.38878203553667456\n",
    "- learning rate: 0.01\n",
    "- max epochs: 10\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_ann_smoteenn_2_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'enn',\n",
    "    'features': [\"gender\", \"dm\", \"ht\", \"sprint\", \"a1c\", \"po4\", \"UACR_mg_g\", \"Cr\", \"age\", \"alb\", \"ca\", \"hb\", \"hco3\"],\n",
    "    'endpoint': 2,\n",
    "    'num_nodes': [8, 4],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.38878203553667456,\n",
    "    'lr': 0.01,\n",
    "    'max_epochs': 10,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.1,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 deepsurv_ann_smotetomek_2\n",
    "- features: ['ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "- sampling_strategy: 0.05\n",
    "- 2 hidden layers with 64, 32 nodes\n",
    "- batch normalization in each hidden layer \n",
    "- dropout ratio in each layer: 0.3162398297390827\n",
    "- learning rate: 0.1\n",
    "- max epochs: 11\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_ann_smotetomek_2_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'tomek',\n",
    "    'features': ['ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 2,\n",
    "    'num_nodes': [64, 32],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.3162398297390827,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 11,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 deepsurv_lstm_clustering_1\n",
    "- features: ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "- sampling_strategy: 0.05\n",
    "- 3 hidden layers with 8, 4, 2 nodes\n",
    "- sequence length 7\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.2772567071863989\n",
    "- learning rate: 0.1\n",
    "- max epochs: 13\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_lstm_clustering_1_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'clustering',\n",
    "    'features': ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [8, 4, 2],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.2772567071863989,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 13,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 deepsurv_lstm_nearmiss_1\n",
    "- features: ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "- sampling_strategy: 0.05\n",
    "- 3 hidden layers with 8, 4, 2 nodes\n",
    "- seq_length': 8\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.3397308077824205\n",
    "- learning rate: 0.001\n",
    "- max epochs: 9\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_lstm_nearmiss_1_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'NearMiss',\n",
    "    'features': ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [8, 4, 2],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.3397308077824205,\n",
    "    'lr': 0.001,\n",
    "    'max_epochs': 9,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 deepsurv_lstm_clustering_2\n",
    "- features: ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "- sampling_strategy: 0.05\n",
    "- 3 hidden layers with 8, 4, 2 nodes\n",
    "- seq_length': 8\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.3397308077824205\n",
    "- learning rate: 0.001\n",
    "- max epochs: 9\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_lstm_clustering_2_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'clustering',\n",
    "    'features': ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr'],\n",
    "    'endpoint': 2,\n",
    "    'num_nodes': [8, 4, 2],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.3397308077824205,\n",
    "    'lr': 0.001,\n",
    "    'max_epochs': 9,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10 deepsurv_lstm_nearmiss_2\n",
    "- features: ['sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "- sampling_strategy: 0.05\n",
    "- 2 hidden layers with 32, 16 nodes\n",
    "- seq_length': 2\n",
    "- no batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.35763396978044143\n",
    "- learning rate: 0.1\n",
    "- max epochs: 10\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsurv_lstm_nearmiss_2_config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'NearMiss',\n",
    "    'features': ['sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 2,\n",
    "    'num_nodes': [32, 16],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.35763396978044143,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 10,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11 deephit_ann_clustering_all\n",
    "- features: ['gender', 'dm', 'ht', 'sprint', 'po4', 'UACR_mg_g', 'Cr', 'age', 'hb', 'hco3']\n",
    "- sampling strategy: 0.05\n",
    "- 2 hidden layers with 64 and 32 nodes\n",
    "- batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.26400151710698067\n",
    "- learning rate: 0.1\n",
    "- max epochs: 8\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deephit_ann_clustering_all_config = {\n",
    "    'model': 'deephit',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'clustering',\n",
    "    'features': ['gender', 'dm', 'ht', 'sprint', 'po4', 'UACR_mg_g', 'Cr', 'age', 'hb', 'hco3'],\n",
    "    'endpoint': 'all',\n",
    "    'num_nodes': [64, 32],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.26400151710698067,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 8,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.12 deephit_ann_nearmiss2_all\n",
    "- features: ['sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "- sampling strategy: 0.05\n",
    "- 2 hidden layers with 8, 4 and 2 nodes\n",
    "- batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.7346754269827496\n",
    "- learning rate: 0.01\n",
    "- max epochs: 7\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deephit_ann_nearmiss2_all_config = {\n",
    "    'model': 'deephit',\n",
    "    'net': 'ann',\n",
    "    'balance_method': 'NearMiss',\n",
    "    'version': 2,\n",
    "    'features': ['sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 'all',\n",
    "    'num_nodes': [8, 4, 2],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.7346754269827496,\n",
    "    'lr': 0.01,\n",
    "    'max_epochs': 7,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.13 deephit_lstm_clustering_all\n",
    "- features: ['ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "- sampling strategy: 0.05\n",
    "- seq_length: 6\n",
    "- 3 hidden layers with 64, 32 and 16 nodes\n",
    "- batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.46132889488306583\n",
    "- learning rate: 0.1\n",
    "- max epochs: 5\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deephit_lstm_clustering_all_config = {\n",
    "    'model': 'deephit',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'clustering',\n",
    "    'version': 2,\n",
    "    'features': ['ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 'all',\n",
    "    'num_nodes': [64, 32, 16],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.46132889488306583,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 5,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.14 deephit_lstm_nearmiss1_all\n",
    "- features: ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "- sampling strategy: 0.05\n",
    "- seq_length: 9\n",
    "- 3 hidden layers with 32, 16 and 8 nodes\n",
    "- batch normalization in each hidden layer\n",
    "- dropout ratio in each layer: 0.18001924589390816\n",
    "- learning rate: 0.1\n",
    "- max epochs: 9\n",
    "- batch size: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deephit_lstm_nearmiss1_all_config = {\n",
    "    'model': 'deephit',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'NearMiss',\n",
    "    'version': 1,\n",
    "    'features': ['gender', 'a1c', 'po4', 'UACR_mg_g', 'Cr'],\n",
    "    'endpoint': 'all',\n",
    "    'num_nodes': [32, 16, 8],\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.18001924589390816,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 9,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ls = ['deepsurv_ann_clustering_1', 'deepsurv_ann_smoteenn_1', 'deepsurv_ann_smotetomek_1',\n",
    "            'deepsurv_ann_clustering_2', 'deepsurv_ann_smoteenn_2', 'deepsurv_ann_smotetomek_2',\n",
    "            'deepsurv_lstm_clustering_1', 'deepsurv_lstm_nearmiss', 'deepsurv_lstm_clustering_2', 'deepsurv_lstm_nearmiss_2',\n",
    "            'deephit_ann_clustering_all', 'deephit_ann_nearmiss2_all', 'deephit_lstm_clustering_all', 'deephit_lstm_nearmiss1_all']\n",
    "model_path = '/mnt/d/PYDataScience/g3_regress/code/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:29,990 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:29,999 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:30,015 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-11 01:11:30,015 - INFO - init\n",
      "2024-11-11 01:11:30,017 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:30,022 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: ANN\n",
      "data balancing method: clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:31,098 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/callbacks.py:607: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  p.data = p.data.add(-weight_decay * eta, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9830,\tval_loss: 7.6472\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.7894,\tval_loss: 7.4912\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.7147,\tval_loss: 7.4432\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.6912,\tval_loss: 7.4037\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.6718,\tval_loss: 7.4363\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.6559,\tval_loss: 7.3902\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.6536,\tval_loss: 7.3836\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 4.6475,\tval_loss: 7.4139\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 4.6416,\tval_loss: 6.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:32,023 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-11 01:11:32,024 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:32,030 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:32,546 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\t[0s / 0s],\t\ttrain_loss: 4.5630,\tval_loss: 6.6073\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 4.5284,\tval_loss: 6.3454\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 4.5609,\tval_loss: 6.6320\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 4.5473,\tval_loss: 6.8888\n",
      "13:\t[0s / 0s],\t\ttrain_loss: 4.5494,\tval_loss: 6.8011\n",
      "14:\t[0s / 0s],\t\ttrain_loss: 4.5360,\tval_loss: 6.4630\n",
      "15:\t[0s / 0s],\t\ttrain_loss: 4.5318,\tval_loss: 6.7356\n",
      "16:\t[0s / 0s],\t\ttrain_loss: 4.5259,\tval_loss: 6.2433\n",
      "17:\t[0s / 0s],\t\ttrain_loss: 4.5288,\tval_loss: 6.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:33,059 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-11 01:11:33,060 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:33,064 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:33,542 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\t[0s / 0s],\t\ttrain_loss: 4.5234,\tval_loss: 6.7651\n",
      "19:\t[0s / 0s],\t\ttrain_loss: 4.5202,\tval_loss: 6.1921\n",
      "20:\t[0s / 0s],\t\ttrain_loss: 4.5133,\tval_loss: 6.7178\n",
      "21:\t[0s / 0s],\t\ttrain_loss: 4.5079,\tval_loss: 6.5168\n",
      "22:\t[0s / 0s],\t\ttrain_loss: 4.5074,\tval_loss: 6.4060\n",
      "23:\t[0s / 0s],\t\ttrain_loss: 4.5092,\tval_loss: 6.4155\n",
      "24:\t[0s / 0s],\t\ttrain_loss: 4.4982,\tval_loss: 6.5076\n",
      "25:\t[0s / 0s],\t\ttrain_loss: 4.5049,\tval_loss: 6.4778\n",
      "26:\t[0s / 0s],\t\ttrain_loss: 4.5045,\tval_loss: 6.4605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:34,043 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-11 01:11:34,044 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:34,048 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:34,492 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27:\t[0s / 0s],\t\ttrain_loss: 4.5468,\tval_loss: 6.2626\n",
      "28:\t[0s / 0s],\t\ttrain_loss: 4.5285,\tval_loss: 6.3278\n",
      "29:\t[0s / 0s],\t\ttrain_loss: 4.5354,\tval_loss: 6.3442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:34,755 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-11 01:11:34,756 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:34,760 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:35,231 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:35,407 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-11 01:11:35,408 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:35,412 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\t[0s / 0s],\t\ttrain_loss: 4.5305,\tval_loss: 6.8553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:35,871 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:36,053 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-11 01:11:36,053 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:36,058 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31:\t[0s / 0s],\t\ttrain_loss: 4.5263,\tval_loss: 6.3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:36,510 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:36,702 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-11 01:11:36,702 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:36,706 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32:\t[0s / 0s],\t\ttrain_loss: 4.5248,\tval_loss: 6.4644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:37,174 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:37,337 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-11 01:11:37,337 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:37,342 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33:\t[0s / 0s],\t\ttrain_loss: 4.5247,\tval_loss: 6.3777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:37,786 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:37,986 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-11 01:11:37,987 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:37,991 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34:\t[0s / 0s],\t\ttrain_loss: 4.5203,\tval_loss: 6.3242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:38,499 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:38,714 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-11 01:11:38,715 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:38,719 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35:\t[0s / 0s],\t\ttrain_loss: 4.5261,\tval_loss: 6.4288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:39,166 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:39,369 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-11 01:11:39,369 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:39,375 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36:\t[0s / 0s],\t\ttrain_loss: 4.5244,\tval_loss: 6.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:39,812 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37:\t[0s / 0s],\t\ttrain_loss: 4.5180,\tval_loss: 6.1555\n",
      "38:\t[0s / 0s],\t\ttrain_loss: 4.5295,\tval_loss: 6.5595\n",
      "39:\t[0s / 0s],\t\ttrain_loss: 4.5377,\tval_loss: 5.9231\n",
      "40:\t[0s / 0s],\t\ttrain_loss: 4.5192,\tval_loss: 6.4159\n",
      "41:\t[0s / 0s],\t\ttrain_loss: 4.5152,\tval_loss: 6.1324\n",
      "42:\t[0s / 0s],\t\ttrain_loss: 4.5171,\tval_loss: 6.0364\n",
      "43:\t[0s / 0s],\t\ttrain_loss: 4.5126,\tval_loss: 6.1844\n",
      "44:\t[0s / 0s],\t\ttrain_loss: 4.5125,\tval_loss: 6.1942\n",
      "45:\t[0s / 0s],\t\ttrain_loss: 4.5036,\tval_loss: 6.0507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:40,406 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-11 01:11:40,407 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:40,411 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:40,920 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46:\t[0s / 0s],\t\ttrain_loss: 4.5302,\tval_loss: 6.3100\n",
      "47:\t[0s / 0s],\t\ttrain_loss: 4.5200,\tval_loss: 6.2886\n",
      "48:\t[0s / 0s],\t\ttrain_loss: 4.5132,\tval_loss: 5.9895\n",
      "49:\t[0s / 0s],\t\ttrain_loss: 4.5187,\tval_loss: 6.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:41,326 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-11 01:11:41,327 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:41,332 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:41,820 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:42,028 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-11 01:11:42,029 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:42,033 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\t[0s / 0s],\t\ttrain_loss: 4.5469,\tval_loss: 6.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:42,505 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:42,693 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-11 01:11:42,694 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:42,697 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51:\t[0s / 0s],\t\ttrain_loss: 4.5249,\tval_loss: 6.3582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:43,144 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:43,350 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-11 01:11:43,351 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:43,354 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52:\t[0s / 0s],\t\ttrain_loss: 4.5187,\tval_loss: 6.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:43,826 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:44,066 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-11 01:11:44,066 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:44,073 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53:\t[0s / 0s],\t\ttrain_loss: 4.5352,\tval_loss: 6.1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:44,538 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:44,732 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-11 01:11:44,732 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:44,736 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54:\t[0s / 0s],\t\ttrain_loss: 4.5292,\tval_loss: 6.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:45,218 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:11:45,434 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-11 01:11:45,435 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:11:45,439 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55:\t[0s / 0s],\t\ttrain_loss: 4.5350,\tval_loss: 6.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:45,890 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:\t[0s / 0s],\t\ttrain_loss: 4.5276,\tval_loss: 5.9846\n",
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_1_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:11:49,339 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:11:49,345 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: ANN\n",
      "data balancing method: smoteenn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "2024-11-11 01:11:53,551 - INFO - Missing values imputed using IterativeImputer.\n",
      "2024-11-11 01:11:53,557 - INFO - Dataframe rebalanced with SMOTE and ENN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[2s / 2s],\t\ttrain_loss: 3.7039,\tval_loss: 5.0026\n",
      "1:\t[2s / 5s],\t\ttrain_loss: 3.6747,\tval_loss: 5.1365\n",
      "2:\t[2s / 8s],\t\ttrain_loss: 3.6364,\tval_loss: 4.9951\n",
      "3:\t[2s / 10s],\t\ttrain_loss: 3.6516,\tval_loss: 4.9670\n",
      "4:\t[2s / 13s],\t\ttrain_loss: 3.6385,\tval_loss: 5.0735\n",
      "5:\t[3s / 16s],\t\ttrain_loss: 3.6231,\tval_loss: 5.0273\n",
      "6:\t[2s / 19s],\t\ttrain_loss: 3.6107,\tval_loss: 5.0000\n",
      "7:\t[2s / 22s],\t\ttrain_loss: 3.6328,\tval_loss: 5.0556\n",
      "8:\t[2s / 25s],\t\ttrain_loss: 3.6288,\tval_loss: 5.0316\n",
      "9:\t[5s / 30s],\t\ttrain_loss: 3.6194,\tval_loss: 4.9399\n",
      "10:\t[2s / 33s],\t\ttrain_loss: 3.6120,\tval_loss: 4.9992\n",
      "11:\t[2s / 36s],\t\ttrain_loss: 3.6053,\tval_loss: 4.9803\n",
      "12:\t[2s / 39s],\t\ttrain_loss: 3.5982,\tval_loss: 5.0213\n",
      "13:\t[2s / 41s],\t\ttrain_loss: 3.5945,\tval_loss: 4.9910\n",
      "14:\t[2s / 44s],\t\ttrain_loss: 3.5897,\tval_loss: 4.9887\n",
      "15:\t[2s / 47s],\t\ttrain_loss: 3.6117,\tval_loss: 5.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_1_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:12:42,068 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:12:42,079 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: ANN\n",
      "data balancing method: smotetomek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "2024-11-11 01:12:46,955 - INFO - Missing values imputed using IterativeImputer.\n",
      "2024-11-11 01:12:46,967 - INFO - Dataframe rebalanced with SMOTE and Tomek.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[3s / 3s],\t\ttrain_loss: 3.6937,\tval_loss: 4.8984\n",
      "1:\t[3s / 6s],\t\ttrain_loss: 3.6496,\tval_loss: 5.1068\n",
      "2:\t[3s / 9s],\t\ttrain_loss: 3.6155,\tval_loss: 4.8960\n",
      "3:\t[5s / 14s],\t\ttrain_loss: 3.6329,\tval_loss: 5.0473\n",
      "4:\t[3s / 17s],\t\ttrain_loss: 3.6244,\tval_loss: 4.9454\n",
      "5:\t[2s / 20s],\t\ttrain_loss: 3.6105,\tval_loss: 4.9168\n",
      "6:\t[3s / 23s],\t\ttrain_loss: 3.5995,\tval_loss: 4.8704\n",
      "7:\t[2s / 26s],\t\ttrain_loss: 3.6258,\tval_loss: 4.8531\n",
      "8:\t[3s / 29s],\t\ttrain_loss: 3.6212,\tval_loss: 4.8991\n",
      "9:\t[3s / 32s],\t\ttrain_loss: 3.6159,\tval_loss: 5.0214\n",
      "10:\t[3s / 35s],\t\ttrain_loss: 3.6119,\tval_loss: 4.9520\n",
      "11:\t[2s / 38s],\t\ttrain_loss: 3.6045,\tval_loss: 4.9148\n",
      "12:\t[3s / 41s],\t\ttrain_loss: 3.6014,\tval_loss: 4.9259\n",
      "13:\t[5s / 46s],\t\ttrain_loss: 3.5973,\tval_loss: 4.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_1_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:34,780 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:13:34,785 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:13:34,792 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-11 01:13:34,793 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:34,797 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: ANN\n",
      "data balancing method: clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:35,467 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.8377,\tval_loss: 7.8246\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.7746,\tval_loss: 7.8049\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.7532,\tval_loss: 7.8124\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.7500,\tval_loss: 7.8242\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.7434,\tval_loss: 7.8194\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.7410,\tval_loss: 7.8201\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.7261,\tval_loss: 7.8172\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 4.7398,\tval_loss: 7.7947\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 4.7344,\tval_loss: 7.7907\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 4.7263,\tval_loss: 7.7879\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 4.7294,\tval_loss: 7.8262\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 4.7218,\tval_loss: 7.8164\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 4.7225,\tval_loss: 7.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:36,647 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-11 01:13:36,647 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:36,651 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:\t[0s / 1s],\t\ttrain_loss: 4.7231,\tval_loss: 7.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:37,093 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:\t[0s / 0s],\t\ttrain_loss: 4.7996,\tval_loss: 7.8146\n",
      "15:\t[0s / 0s],\t\ttrain_loss: 4.7748,\tval_loss: 7.8052\n",
      "16:\t[0s / 0s],\t\ttrain_loss: 4.7459,\tval_loss: 7.8373\n",
      "17:\t[0s / 0s],\t\ttrain_loss: 4.7464,\tval_loss: 7.8240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:37,613 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-11 01:13:37,613 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:37,618 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\t[0s / 0s],\t\ttrain_loss: 4.7450,\tval_loss: 7.8250\n",
      "19:\t[0s / 0s],\t\ttrain_loss: 4.7419,\tval_loss: 7.8279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:38,039 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:38,229 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-11 01:13:38,230 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:38,234 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:\t[0s / 0s],\t\ttrain_loss: 4.8583,\tval_loss: 7.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:38,650 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:\t[0s / 0s],\t\ttrain_loss: 5.0357,\tval_loss: 7.7539\n",
      "22:\t[0s / 0s],\t\ttrain_loss: 5.0232,\tval_loss: 7.7552\n",
      "23:\t[0s / 0s],\t\ttrain_loss: 5.0247,\tval_loss: 7.7596\n",
      "24:\t[0s / 0s],\t\ttrain_loss: 5.0237,\tval_loss: 7.7566\n",
      "25:\t[0s / 0s],\t\ttrain_loss: 5.0254,\tval_loss: 7.7562\n",
      "26:\t[0s / 0s],\t\ttrain_loss: 5.0245,\tval_loss: 7.7558\n",
      "27:\t[0s / 0s],\t\ttrain_loss: 5.0276,\tval_loss: 7.7559\n",
      "28:\t[0s / 0s],\t\ttrain_loss: 5.0248,\tval_loss: 7.7562\n",
      "29:\t[0s / 0s],\t\ttrain_loss: 5.0239,\tval_loss: 7.7564\n",
      "30:\t[0s / 0s],\t\ttrain_loss: 5.0212,\tval_loss: 7.7571\n",
      "31:\t[0s / 0s],\t\ttrain_loss: 5.0254,\tval_loss: 7.7538\n",
      "32:\t[0s / 0s],\t\ttrain_loss: 5.0254,\tval_loss: 7.7577\n",
      "33:\t[0s / 0s],\t\ttrain_loss: 5.0249,\tval_loss: 7.7574\n",
      "34:\t[0s / 0s],\t\ttrain_loss: 5.0273,\tval_loss: 7.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:39,654 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-11 01:13:39,655 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:39,658 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:13:40,070 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35:\t[0s / 0s],\t\ttrain_loss: 5.0410,\tval_loss: 7.7629\n",
      "36:\t[0s / 0s],\t\ttrain_loss: 5.0320,\tval_loss: 7.7625\n",
      "37:\t[0s / 0s],\t\ttrain_loss: 5.0372,\tval_loss: 7.7558\n",
      "38:\t[0s / 0s],\t\ttrain_loss: 5.0327,\tval_loss: 7.7621\n",
      "39:\t[0s / 0s],\t\ttrain_loss: 5.0326,\tval_loss: 7.7584\n",
      "40:\t[0s / 0s],\t\ttrain_loss: 5.0289,\tval_loss: 7.7618\n",
      "41:\t[0s / 0s],\t\ttrain_loss: 5.0335,\tval_loss: 7.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:40,636 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-11 01:13:40,636 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:40,640 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:13:41,033 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42:\t[0s / 0s],\t\ttrain_loss: 5.0511,\tval_loss: 7.7513\n",
      "43:\t[0s / 0s],\t\ttrain_loss: 5.0472,\tval_loss: 7.7513\n",
      "44:\t[0s / 0s],\t\ttrain_loss: 5.0537,\tval_loss: 7.7513\n",
      "45:\t[0s / 0s],\t\ttrain_loss: 5.0533,\tval_loss: 7.7513\n",
      "46:\t[0s / 0s],\t\ttrain_loss: 5.0481,\tval_loss: 7.7514\n",
      "47:\t[0s / 0s],\t\ttrain_loss: 5.0486,\tval_loss: 7.7513\n",
      "48:\t[0s / 0s],\t\ttrain_loss: 5.0528,\tval_loss: 7.7513\n",
      "49:\t[0s / 0s],\t\ttrain_loss: 5.0505,\tval_loss: 7.7514\n",
      "50:\t[0s / 0s],\t\ttrain_loss: 5.0523,\tval_loss: 7.7514\n",
      "51:\t[0s / 0s],\t\ttrain_loss: 5.0442,\tval_loss: 7.7513\n",
      "52:\t[0s / 0s],\t\ttrain_loss: 5.0488,\tval_loss: 7.7513\n",
      "53:\t[0s / 0s],\t\ttrain_loss: 5.0467,\tval_loss: 7.7513\n",
      "54:\t[0s / 0s],\t\ttrain_loss: 5.0508,\tval_loss: 7.7513\n",
      "55:\t[0s / 0s],\t\ttrain_loss: 5.0500,\tval_loss: 7.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:42,127 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-11 01:13:42,128 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:42,131 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:13:42,522 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:\t[0s / 0s],\t\ttrain_loss: 5.0576,\tval_loss: 7.7513\n",
      "57:\t[0s / 0s],\t\ttrain_loss: 5.0590,\tval_loss: 7.7514\n",
      "58:\t[0s / 0s],\t\ttrain_loss: 5.0585,\tval_loss: 7.7514\n",
      "59:\t[0s / 0s],\t\ttrain_loss: 5.0570,\tval_loss: 7.7514\n",
      "60:\t[0s / 0s],\t\ttrain_loss: 5.0552,\tval_loss: 7.7514\n",
      "61:\t[0s / 0s],\t\ttrain_loss: 5.0564,\tval_loss: 7.7514\n",
      "62:\t[0s / 0s],\t\ttrain_loss: 5.0568,\tval_loss: 7.7514\n",
      "63:\t[0s / 0s],\t\ttrain_loss: 5.0535,\tval_loss: 7.7542\n",
      "64:\t[0s / 0s],\t\ttrain_loss: 5.0596,\tval_loss: 7.7514\n",
      "65:\t[0s / 0s],\t\ttrain_loss: 5.0576,\tval_loss: 7.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:43,302 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-11 01:13:43,303 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:43,307 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:13:43,683 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:43,883 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-11 01:13:43,883 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:43,888 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66:\t[0s / 0s],\t\ttrain_loss: 5.0576,\tval_loss: 7.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:44,247 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:44,462 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-11 01:13:44,463 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:44,466 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67:\t[0s / 0s],\t\ttrain_loss: 5.0770,\tval_loss: 7.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:44,871 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:45,095 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-11 01:13:45,095 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:45,099 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68:\t[0s / 0s],\t\ttrain_loss: 5.0887,\tval_loss: 7.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:45,451 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69:\t[0s / 0s],\t\ttrain_loss: 5.0887,\tval_loss: 7.7524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:45,752 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-11 01:13:45,753 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:45,758 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:13:46,132 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:46,368 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-11 01:13:46,369 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:46,373 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70:\t[0s / 0s],\t\ttrain_loss: 5.0805,\tval_loss: 7.7562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:46,705 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:46,958 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-11 01:13:46,959 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:46,964 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71:\t[0s / 0s],\t\ttrain_loss: 5.1157,\tval_loss: 7.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:47,350 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:47,588 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-11 01:13:47,589 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:47,594 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72:\t[0s / 0s],\t\ttrain_loss: 5.1057,\tval_loss: 7.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:47,945 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:48,183 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-11 01:13:48,183 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:48,188 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73:\t[0s / 0s],\t\ttrain_loss: 5.0863,\tval_loss: 7.7556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:48,537 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:48,790 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-11 01:13:48,791 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:48,794 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74:\t[0s / 0s],\t\ttrain_loss: 5.1062,\tval_loss: 7.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:49,108 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:49,313 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-11 01:13:49,314 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:49,318 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75:\t[0s / 0s],\t\ttrain_loss: 5.1011,\tval_loss: 7.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:49,619 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:49,817 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-11 01:13:49,817 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:49,821 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76:\t[0s / 0s],\t\ttrain_loss: 5.1087,\tval_loss: 7.7561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:50,095 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:13:50,294 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-11 01:13:50,295 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:13:50,298 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77:\t[0s / 0s],\t\ttrain_loss: 5.0830,\tval_loss: 7.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:50,565 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78:\t[0s / 0s],\t\ttrain_loss: 5.1019,\tval_loss: 7.7563\n",
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_2_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:13:51,577 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:13:51,583 - INFO - Event column 'endpoint' updated with focus on event value 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: ANN\n",
      "data balancing method: smoteenn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "2024-11-11 01:13:55,883 - INFO - Missing values imputed using IterativeImputer.\n",
      "2024-11-11 01:13:55,889 - INFO - Dataframe rebalanced with SMOTE and ENN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[2s / 2s],\t\ttrain_loss: 4.9248,\tval_loss: 7.6376\n",
      "1:\t[2s / 4s],\t\ttrain_loss: 4.8521,\tval_loss: 7.5118\n",
      "2:\t[2s / 6s],\t\ttrain_loss: 4.8133,\tval_loss: 7.5078\n",
      "3:\t[2s / 8s],\t\ttrain_loss: 4.8133,\tval_loss: 7.4827\n",
      "4:\t[4s / 13s],\t\ttrain_loss: 4.8067,\tval_loss: 7.4808\n",
      "5:\t[2s / 15s],\t\ttrain_loss: 4.7945,\tval_loss: 7.4821\n",
      "6:\t[2s / 18s],\t\ttrain_loss: 4.7994,\tval_loss: 7.4787\n",
      "7:\t[2s / 20s],\t\ttrain_loss: 4.7979,\tval_loss: 7.4919\n",
      "8:\t[2s / 22s],\t\ttrain_loss: 4.8081,\tval_loss: 7.4771\n",
      "9:\t[2s / 24s],\t\ttrain_loss: 4.7931,\tval_loss: 7.4882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_2_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:14:21,246 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:14:21,254 - INFO - Event column 'endpoint' updated with focus on event value 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: ANN\n",
      "data balancing method: smotetomek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "2024-11-11 01:14:25,733 - INFO - Missing values imputed using IterativeImputer.\n",
      "2024-11-11 01:14:25,742 - INFO - Dataframe rebalanced with SMOTE and Tomek.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[2s / 2s],\t\ttrain_loss: 4.6971,\tval_loss: 7.4266\n",
      "1:\t[2s / 5s],\t\ttrain_loss: 4.6767,\tval_loss: 7.4766\n",
      "2:\t[2s / 7s],\t\ttrain_loss: 4.6137,\tval_loss: 7.4052\n",
      "3:\t[2s / 10s],\t\ttrain_loss: 4.6696,\tval_loss: 7.4253\n",
      "4:\t[2s / 12s],\t\ttrain_loss: 4.6354,\tval_loss: 7.4492\n",
      "5:\t[4s / 17s],\t\ttrain_loss: 4.6036,\tval_loss: 7.3843\n",
      "6:\t[2s / 20s],\t\ttrain_loss: 4.5856,\tval_loss: 7.4143\n",
      "7:\t[2s / 22s],\t\ttrain_loss: 4.6285,\tval_loss: 7.3914\n",
      "8:\t[2s / 25s],\t\ttrain_loss: 4.6278,\tval_loss: 7.4165\n",
      "9:\t[2s / 27s],\t\ttrain_loss: 4.6162,\tval_loss: 7.4229\n",
      "10:\t[2s / 30s],\t\ttrain_loss: 4.6005,\tval_loss: 7.4228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_2_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:14:57,049 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:14:57,171 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-11 01:14:57,171 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:14:57,178 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: LSTM\n",
      "data balancing method: clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:14:57,851 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:14:57,852 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-11 01:14:57,853 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:14:57,856 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:14:58,286 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:14:58,287 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-11 01:14:58,288 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:14:58,291 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:14:58,748 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:14:58,749 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-11 01:14:58,750 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:14:58,753 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:14:59,196 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:14:59,197 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-11 01:14:59,197 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:14:59,201 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:14:59,635 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:14:59,637 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-11 01:14:59,637 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:14:59,640 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:00,096 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:00,097 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-11 01:15:00,098 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:00,101 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:00,523 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:00,524 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-11 01:15:00,525 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:00,528 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:00,974 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:00,974 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-11 01:15:00,975 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:00,979 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:01,419 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:01,421 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-11 01:15:01,421 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:01,425 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:01,885 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:01,886 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-11 01:15:01,887 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:01,891 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:02,359 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:02,361 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-11 01:15:02,362 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:02,365 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:02,782 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:02,783 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-11 01:15:02,783 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:02,786 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:03,210 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:03,212 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-11 01:15:03,212 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:03,215 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:03,622 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:03,622 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-11 01:15:03,623 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:03,626 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:04,034 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:04,036 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-11 01:15:04,037 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:04,040 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:04,457 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:04,458 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-11 01:15:04,459 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:04,462 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:04,855 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:04,856 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-11 01:15:04,857 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:04,860 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:05,257 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:05,258 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-11 01:15:05,259 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:05,262 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:05,650 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:05,651 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-11 01:15:05,651 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:15:05,655 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:06,037 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:15:06,050 - INFO - Cluster data retrieved\n",
      "2024-11-11 01:15:29,097 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:15:56,332 - INFO - Validation data retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.5617,\tval_loss: 7.2081\n",
      "1:\t[0s / 1s],\t\ttrain_loss: 2.9387,\tval_loss: 5.9918\n",
      "2:\t[0s / 2s],\t\ttrain_loss: 2.4066,\tval_loss: 5.3972\n",
      "3:\t[0s / 3s],\t\ttrain_loss: 2.6390,\tval_loss: 6.5935\n",
      "4:\t[0s / 4s],\t\ttrain_loss: 2.5702,\tval_loss: 5.2999\n",
      "5:\t[0s / 4s],\t\ttrain_loss: 2.3631,\tval_loss: 5.1957\n",
      "6:\t[0s / 5s],\t\ttrain_loss: 2.3455,\tval_loss: 5.1295\n",
      "7:\t[0s / 6s],\t\ttrain_loss: 2.3875,\tval_loss: 5.1657\n",
      "8:\t[0s / 7s],\t\ttrain_loss: 2.3445,\tval_loss: 5.6417\n",
      "9:\t[0s / 8s],\t\ttrain_loss: 2.3155,\tval_loss: 5.8319\n",
      "10:\t[0s / 9s],\t\ttrain_loss: 2.2676,\tval_loss: 5.7024\n",
      "11:\t[1s / 10s],\t\ttrain_loss: 2.1691,\tval_loss: 5.3814\n",
      "12:\t[1s / 11s],\t\ttrain_loss: 2.1433,\tval_loss: 5.2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_1_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n",
      "Configuration for deepsurv_lstm_nearmiss_config not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:16:08,806 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:08,942 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-11 01:16:08,944 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:08,956 - INFO - Event column 'endpoint' updated with focus on event value 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: LSTM\n",
      "data balancing method: clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:16:09,540 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:09,543 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-11 01:16:09,544 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:09,550 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:10,037 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:10,038 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-11 01:16:10,038 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:10,043 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:10,512 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:10,514 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-11 01:16:10,514 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:10,518 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:10,950 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:10,951 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-11 01:16:10,951 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:10,955 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:11,401 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:11,402 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-11 01:16:11,403 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:11,406 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:11,862 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:11,863 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-11 01:16:11,863 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:11,867 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:12,280 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:12,282 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-11 01:16:12,282 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:12,286 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:12,688 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:12,689 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-11 01:16:12,689 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:12,692 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:13,080 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:13,082 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-11 01:16:13,082 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:13,085 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:13,476 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:13,477 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-11 01:16:13,477 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:13,480 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:13,863 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:13,864 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-11 01:16:13,864 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:13,867 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:14,211 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:14,212 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-11 01:16:14,213 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:14,216 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:14,579 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:14,581 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-11 01:16:14,582 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:14,585 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:14,914 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:14,915 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-11 01:16:14,916 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:14,920 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:15,294 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:15,296 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-11 01:16:15,296 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:15,299 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:15,643 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:15,644 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-11 01:16:15,644 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:15,647 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:15,964 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:15,966 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-11 01:16:15,966 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:15,969 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:16,267 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:16,268 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-11 01:16:16,269 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:16,273 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:16,552 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:16,553 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-11 01:16:16,554 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:16:16,557 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:16:16,874 - INFO - Defined medoid for deepsurv model with 3725 clusters.\n",
      "2024-11-11 01:16:16,909 - INFO - Cluster data retrieved\n",
      "2024-11-11 01:17:20,914 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:17:47,771 - INFO - Validation data retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[1s / 1s],\t\ttrain_loss: 4.9825\n",
      "1:\t[1s / 3s],\t\ttrain_loss: 4.9802\n",
      "2:\t[1s / 4s],\t\ttrain_loss: 4.9777\n",
      "3:\t[1s / 6s],\t\ttrain_loss: 4.9773\n",
      "4:\t[1s / 8s],\t\ttrain_loss: 4.9466\n",
      "5:\t[1s / 9s],\t\ttrain_loss: 4.9355\n",
      "6:\t[1s / 11s],\t\ttrain_loss: 4.9283\n",
      "7:\t[1s / 12s],\t\ttrain_loss: 4.9099\n",
      "8:\t[1s / 14s],\t\ttrain_loss: 4.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_2_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:18:02,797 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "/mnt/d/PYDataScience/g3_regress/code/databalancer2.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_original_index'] = df.index\n",
      "2024-11-11 01:18:02,932 - INFO - Event column 'endpoint' updated with focus on event value 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deepsurv neural network\n",
      "model structure: LSTM\n",
      "data balancing method: NearMiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/under_sampling/_prototype_selection/_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "2024-11-11 01:18:03,270 - INFO - Dataset for deepsurv model undersampled using method 'NearMiss' with sampling strategy 0.05.\n",
      "2024-11-11 01:18:36,969 - INFO - Event column 'endpoint' updated with focus on event value 2.\n",
      "2024-11-11 01:19:13,194 - INFO - Validation data retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 5.0475\n",
      "1:\t[0s / 1s],\t\ttrain_loss: 5.0110\n",
      "2:\t[0s / 1s],\t\ttrain_loss: 4.9827\n",
      "3:\t[0s / 2s],\t\ttrain_loss: 5.0092\n",
      "4:\t[0s / 3s],\t\ttrain_loss: 4.9928\n",
      "5:\t[0s / 3s],\t\ttrain_loss: 4.9793\n",
      "6:\t[2s / 6s],\t\ttrain_loss: 4.9707\n",
      "7:\t[0s / 7s],\t\ttrain_loss: 4.9829\n",
      "8:\t[0s / 7s],\t\ttrain_loss: 5.0025\n",
      "9:\t[0s / 8s],\t\ttrain_loss: 4.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_nearmiss_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_nearmiss_2_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:22,601 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-11 01:19:22,602 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deephit neural network\n",
      "model structure: ANN\n",
      "data balancing method: clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:23,287 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 0.4790,\tval_loss: 0.0682\n",
      "1:\t[0s / 1s],\t\ttrain_loss: 0.3757,\tval_loss: 0.0837\n",
      "2:\t[0s / 1s],\t\ttrain_loss: 0.3531,\tval_loss: 0.0777\n",
      "3:\t[0s / 2s],\t\ttrain_loss: 0.3406,\tval_loss: 0.0724\n",
      "4:\t[0s / 2s],\t\ttrain_loss: 0.3315,\tval_loss: 0.0695\n",
      "5:\t[0s / 3s],\t\ttrain_loss: 0.3265,\tval_loss: 0.0703\n",
      "6:\t[0s / 3s],\t\ttrain_loss: 0.3247,\tval_loss: 0.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:28,126 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-11 01:19:28,126 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7:\t[0s / 4s],\t\ttrain_loss: 0.3287,\tval_loss: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:28,563 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:\t[0s / 0s],\t\ttrain_loss: 0.4116,\tval_loss: 0.0737\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.3832,\tval_loss: 0.0633\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 0.3494,\tval_loss: 0.0583\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.3435,\tval_loss: 0.0605\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.3386,\tval_loss: 0.0622\n",
      "13:\t[0s / 3s],\t\ttrain_loss: 0.3354,\tval_loss: 0.0640\n",
      "14:\t[0s / 3s],\t\ttrain_loss: 0.3358,\tval_loss: 0.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:33,066 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-11 01:19:33,066 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:\t[0s / 4s],\t\ttrain_loss: 0.3330,\tval_loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:33,480 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:\t[0s / 0s],\t\ttrain_loss: 0.3407,\tval_loss: 0.0590\n",
      "17:\t[0s / 1s],\t\ttrain_loss: 0.3331,\tval_loss: 0.0658\n",
      "18:\t[0s / 1s],\t\ttrain_loss: 0.3281,\tval_loss: 0.0605\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 0.3256,\tval_loss: 0.0645\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 0.3244,\tval_loss: 0.0620\n",
      "21:\t[0s / 3s],\t\ttrain_loss: 0.3238,\tval_loss: 0.0618\n",
      "22:\t[0s / 3s],\t\ttrain_loss: 0.3241,\tval_loss: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:37,883 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-11 01:19:37,884 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:\t[0s / 4s],\t\ttrain_loss: 0.3217,\tval_loss: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:38,302 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24:\t[0s / 0s],\t\ttrain_loss: 0.3375,\tval_loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:39,542 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-11 01:19:39,542 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25:\t[0s / 1s],\t\ttrain_loss: 0.3302,\tval_loss: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:39,982 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:40,656 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-11 01:19:40,656 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26:\t[0s / 0s],\t\ttrain_loss: 0.3379,\tval_loss: 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:41,038 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:41,771 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-11 01:19:41,771 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27:\t[0s / 0s],\t\ttrain_loss: 0.3419,\tval_loss: 0.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:42,170 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:42,885 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-11 01:19:42,886 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28:\t[0s / 0s],\t\ttrain_loss: 0.3477,\tval_loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:43,277 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:43,983 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-11 01:19:43,984 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29:\t[0s / 0s],\t\ttrain_loss: 0.3492,\tval_loss: 0.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:44,368 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\t[0s / 0s],\t\ttrain_loss: 0.3674,\tval_loss: 0.0508\n",
      "31:\t[0s / 1s],\t\ttrain_loss: 0.3583,\tval_loss: 0.0511\n",
      "32:\t[0s / 1s],\t\ttrain_loss: 0.3464,\tval_loss: 0.0609\n",
      "33:\t[0s / 2s],\t\ttrain_loss: 0.3377,\tval_loss: 0.0602\n",
      "34:\t[0s / 2s],\t\ttrain_loss: 0.3343,\tval_loss: 0.0580\n",
      "35:\t[0s / 3s],\t\ttrain_loss: 0.3348,\tval_loss: 0.0552\n",
      "36:\t[0s / 3s],\t\ttrain_loss: 0.3330,\tval_loss: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:48,967 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-11 01:19:48,968 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37:\t[0s / 4s],\t\ttrain_loss: 0.3307,\tval_loss: 0.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:49,362 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38:\t[0s / 0s],\t\ttrain_loss: 0.3501,\tval_loss: 0.0610\n",
      "39:\t[0s / 1s],\t\ttrain_loss: 0.3385,\tval_loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:51,174 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-11 01:19:51,175 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40:\t[0s / 1s],\t\ttrain_loss: 0.3378,\tval_loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:51,554 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:54,454 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-11 01:19:54,455 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41:\t[2s / 2s],\t\ttrain_loss: 0.3508,\tval_loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:54,767 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:55,432 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-11 01:19:55,433 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42:\t[0s / 0s],\t\ttrain_loss: 0.3518,\tval_loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:55,775 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:56,450 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-11 01:19:56,451 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43:\t[0s / 0s],\t\ttrain_loss: 0.3481,\tval_loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:56,798 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:57,535 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-11 01:19:57,536 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44:\t[0s / 0s],\t\ttrain_loss: 0.3506,\tval_loss: 0.0617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:57,829 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:58,520 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-11 01:19:58,521 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45:\t[0s / 0s],\t\ttrain_loss: 0.3534,\tval_loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:58,784 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:19:59,584 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-11 01:19:59,585 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46:\t[0s / 0s],\t\ttrain_loss: 0.3536,\tval_loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:19:59,839 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:20:00,630 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-11 01:20:00,631 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47:\t[0s / 0s],\t\ttrain_loss: 0.3515,\tval_loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:20:00,887 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48:\t[0s / 0s],\t\ttrain_loss: 0.3550,\tval_loss: 0.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:20:01,788 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-11 01:20:01,789 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:02,042 - INFO - Defined medoid for deephit model with 4932 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-11 01:20:02,938 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-11 01:20:02,938 - INFO - CUDA environment set up and GPU memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49:\t[0s / 0s],\t\ttrain_loss: 0.3567,\tval_loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:20:03,182 - INFO - Defined medoid for deephit model with 4932 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\t[0s / 0s],\t\ttrain_loss: 0.3539,\tval_loss: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_clustering_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_clustering_all_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n",
      "Initiate training of deephit neural network\n",
      "model structure: ANN\n",
      "data balancing method: NearMiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/PYDataScience/g3_regress/code/databalancer2.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_original_index'] = df.index\n",
      "2024-11-11 01:20:16,008 - INFO - Dataset for deephit model undersampled using method 'NearMiss' with sampling strategy 0.05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[2s / 2s],\t\ttrain_loss: 0.1217,\tval_loss: 0.0696\n",
      "1:\t[1s / 4s],\t\ttrain_loss: 0.0738,\tval_loss: 0.0373\n",
      "2:\t[1s / 6s],\t\ttrain_loss: 0.0619,\tval_loss: 0.0344\n",
      "3:\t[2s / 8s],\t\ttrain_loss: 0.0578,\tval_loss: 0.0281\n",
      "4:\t[1s / 9s],\t\ttrain_loss: 0.0555,\tval_loss: 0.0273\n",
      "5:\t[4s / 14s],\t\ttrain_loss: 0.0549,\tval_loss: 0.0270\n",
      "6:\t[1s / 16s],\t\ttrain_loss: 0.0549,\tval_loss: 0.0270\n",
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_nearmiss2_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_nearmiss2_all_hazard.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:20:33,628 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-11 01:20:33,628 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:33,633 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate training of deephit neural network\n",
      "model structure: LSTM\n",
      "data balancing method: clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 01:20:34,101 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:34,103 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-11 01:20:34,103 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:34,106 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:34,620 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:34,621 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-11 01:20:34,622 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:34,625 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:35,080 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:35,082 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-11 01:20:35,083 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:35,086 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:35,534 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:35,536 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-11 01:20:35,538 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:35,542 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:35,997 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:35,999 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-11 01:20:36,000 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:36,003 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:36,485 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:36,486 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-11 01:20:36,486 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:36,490 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:36,976 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:36,979 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-11 01:20:36,979 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:36,983 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:37,443 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:37,443 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-11 01:20:37,444 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:37,448 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:37,890 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:37,891 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-11 01:20:37,892 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:37,896 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:38,417 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:38,417 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-11 01:20:38,418 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:38,422 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:38,838 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:38,840 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-11 01:20:38,840 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:38,843 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:39,321 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:39,322 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-11 01:20:39,323 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:39,326 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:39,744 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:39,746 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-11 01:20:39,746 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:39,749 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:40,245 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:40,246 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-11 01:20:40,247 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:40,249 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:40,650 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:40,652 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-11 01:20:40,652 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:40,656 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:41,068 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:41,069 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-11 01:20:41,070 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:41,074 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:41,510 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:41,512 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-11 01:20:41,513 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:41,516 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:41,903 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:41,904 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-11 01:20:41,904 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:41,907 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:42,306 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:42,308 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-11 01:20:42,308 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-11 01:20:42,311 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-11 01:20:42,706 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-11 01:20:42,719 - INFO - Cluster data retrieved\n",
      "2024-11-11 01:22:24,064 - INFO - Validation data retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[1s / 1s],\t\ttrain_loss: 0.0546,\tval_loss: 0.0508\n",
      "1:\t[1s / 3s],\t\ttrain_loss: 0.0422,\tval_loss: 0.0467\n",
      "2:\t[1s / 5s],\t\ttrain_loss: 0.0285,\tval_loss: 0.0505\n",
      "3:\t[1s / 7s],\t\ttrain_loss: 0.0338,\tval_loss: 0.0507\n",
      "4:\t[1s / 9s],\t\ttrain_loss: 0.0263,\tval_loss: 0.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_clustering_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_clustering_all_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n",
      "Initiate training of deephit neural network\n",
      "model structure: LSTM\n",
      "data balancing method: NearMiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/PYDataScience/g3_regress/code/databalancer2.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_original_index'] = df.index\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/under_sampling/_prototype_selection/_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/imblearn/under_sampling/_prototype_selection/_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n",
      "2024-11-11 01:22:34,957 - INFO - Dataset for deephit model undersampled using method 'NearMiss' with sampling strategy 0.05.\n",
      "2024-11-11 01:23:12,848 - INFO - Validation data retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[1s / 1s],\t\ttrain_loss: 0.4642,\tval_loss: 0.0951\n",
      "1:\t[1s / 2s],\t\ttrain_loss: 0.4103,\tval_loss: 0.0848\n",
      "2:\t[1s / 4s],\t\ttrain_loss: 0.3984,\tval_loss: 0.0821\n",
      "3:\t[1s / 5s],\t\ttrain_loss: 0.3965,\tval_loss: 0.0723\n",
      "4:\t[1s / 6s],\t\ttrain_loss: 0.3833,\tval_loss: 0.0728\n",
      "5:\t[1s / 8s],\t\ttrain_loss: 0.3557,\tval_loss: 0.0676\n",
      "6:\t[3s / 12s],\t\ttrain_loss: 0.3368,\tval_loss: 0.0642\n",
      "7:\t[1s / 13s],\t\ttrain_loss: 0.3466,\tval_loss: 0.0571\n",
      "8:\t[1s / 15s],\t\ttrain_loss: 0.3259,\tval_loss: 0.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards saved to /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_nearmiss1_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_nearmiss1_all_hazard.pkl.\n",
      "Training and saving completed for all cross-validation splits.\n",
      "All models have been trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "for train_idx_1, fin_val_idx in gss1.split(X=X_train_transformed[FEATURE_COLS], y=X_train_transformed[EVENT_COL], groups=X_train_transformed[CLUSTER_COL]):\n",
    "    X_train_transformed_2, X_fin_val = X_train_transformed.iloc[train_idx_1, :], X_train_transformed.iloc[fin_val_idx, :]\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    for model in model_ls:\n",
    "        config_var_name = model + \"_config\"\n",
    "        model_config = globals().get(config_var_name)\n",
    "        if model_config is None:\n",
    "            print(f\"Configuration for {config_var_name} not found.\")\n",
    "            continue\n",
    "\n",
    "        model_weights_path = f'{model_path}{model}.pt'\n",
    "        model_hazard_path = f'{model_path}{model}_hazard.pkl'\n",
    "        \n",
    "        training_wrapper(X_train_transformed_2, model_config, gss2, model_weights_path, \n",
    "                        model_hazard_path, \n",
    "                        feature_col=FEATURE_COLS, duration_col=DURATION_COL, event_col=EVENT_COL, cluster_col=CLUSTER_COL, time_grid=TIME_GRID)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load models amd hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_config, model_path, baseline_hazard_path):\n",
    "    \"\"\"\n",
    "    Load model weights and baseline hazard data.\n",
    "\n",
    "    Parameters:\n",
    "    - create_model_func: Function to create the model architecture (e.g., create_neural_network).\n",
    "    - model_path: Path to load the model weights (.pt file).\n",
    "    - baseline_hazard_path: Path to load the baseline hazards (.pkl file).\n",
    "\n",
    "    Returns:\n",
    "    - model: The loaded model with weights and baseline hazards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_model_weights(model_path)\n",
    "    \n",
    "    # Load baseline hazards and assign to model\n",
    "    if model_config['model'] == 'deepsurv':\n",
    "        baseline_hazard = pd.read_pickle(baseline_hazard_path)\n",
    "        model.baseline_hazards_ = baseline_hazard\n",
    "        model.baseline_cumulative_hazards_ = baseline_hazard.cumsum()\n",
    "    \n",
    "    print(f\"Model and baseline hazards loaded from {model_path} and {baseline_hazard_path}.\")\n",
    "    return model\n",
    "\n",
    "# model_ls = ['deepsurv_ann_clustering_1', 'deepsurv_ann_smoteenn_1', 'deepsurv_ann_smotetomek_1',\n",
    "#             'deepsurv_ann_clustering_2', 'deepsurv_ann_smoteenn_2', 'deepsurv_ann_smotetomek_2',\n",
    "#             'deepsurv_lstm_clustering_1', 'deepsurv_lstm_nearmiss', 'deepsurv_lstm_clustering_2', 'deepsurv_lstm_nearmiss_2',\n",
    "#             'deephit_ann_clustering_all', 'deephit_ann_nearmiss2_all', 'deephit_lstm_clustering_all', 'deephit_lstm_nearmiss1_all']\n",
    "# model_path = '/mnt/d/PYDataScience/g3_regress/code/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_1_hazard.pkl.\n",
      "Loaded model deepsurv_ann_clustering_1\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_1_hazard.pkl.\n",
      "Loaded model deepsurv_ann_smoteenn_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_1_hazard.pkl.\n",
      "Loaded model deepsurv_ann_smotetomek_1\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_clustering_2_hazard.pkl.\n",
      "Loaded model deepsurv_ann_clustering_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smoteenn_2_hazard.pkl.\n",
      "Loaded model deepsurv_ann_smoteenn_2\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_ann_smotetomek_2_hazard.pkl.\n",
      "Loaded model deepsurv_ann_smotetomek_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_1.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_1_hazard.pkl.\n",
      "Loaded model deepsurv_lstm_clustering_1\n",
      "Configuration for deepsurv_lstm_nearmiss_config not found.\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_clustering_2_hazard.pkl.\n",
      "Loaded model deepsurv_lstm_clustering_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_nearmiss_2.pt and /mnt/d/PYDataScience/g3_regress/code/models/deepsurv_lstm_nearmiss_2_hazard.pkl.\n",
      "Loaded model deepsurv_lstm_nearmiss_2\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_clustering_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_clustering_all_hazard.pkl.\n",
      "Loaded model deephit_ann_clustering_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_nearmiss2_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_ann_nearmiss2_all_hazard.pkl.\n",
      "Loaded model deephit_ann_nearmiss2_all\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_clustering_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_clustering_all_hazard.pkl.\n",
      "Loaded model deephit_lstm_clustering_all\n",
      "Model and baseline hazards loaded from /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_nearmiss1_all.pt and /mnt/d/PYDataScience/g3_regress/code/models/deephit_lstm_nearmiss1_all_hazard.pkl.\n",
      "Loaded model deephit_lstm_nearmiss1_all\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store loaded models\n",
    "loaded_models = {}\n",
    "\n",
    "for model_name in model_ls:\n",
    "    # Retrieve configuration by dynamically constructing the variable name\n",
    "    config_var_name = model_name + \"_config\"\n",
    "    model_config = globals().get(config_var_name)\n",
    "    \n",
    "    if model_config is None:\n",
    "        print(f\"Configuration for {config_var_name} not found.\")\n",
    "        continue\n",
    "\n",
    "    model_weights_path = f'{model_path}{model_name}.pt'\n",
    "    model_hazard_path = f'{model_path}{model_name}_hazard.pkl'\n",
    "    \n",
    "    # Define the model creation function as a lambda to pass the config\n",
    "    create_model_func = lambda: create_neural_network(\n",
    "        config=model_config,\n",
    "        num_risk=len(X_train_transformed[EVENT_COL].unique()) - 1,\n",
    "        num_time_bins=len(TIME_GRID)\n",
    "    )\n",
    "    model = create_model_func()\n",
    "    \n",
    "    # Load the model and store it in the dictionary\n",
    "    loaded_models[model_name] = load_model(model, model_config, model_weights_path, model_hazard_path)\n",
    "    print(f'Loaded model {model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepare test dataset and make prediction on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_neural_network(model, config, X_test, duration_col, event_col, cluster_col, time_grid=None):\n",
    "    \"\"\"\n",
    "    Function to train a given neural network using the provided datasets.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): Neural network to be trained.\n",
    "        config (dict): Configuration dictionary containing model hyperparameters.\n",
    "        X_train (pd.DataFrame): Training dataset with features.\n",
    "        X_val (pd.DataFrame): Validation dataset with features.\n",
    "        duration_col (str): Column representing event durations.\n",
    "        event_col (str): Column representing event occurrences.\n",
    "        cluster_col (str): Column for grouping during cross-validation.\n",
    "        callbacks (list): List of callbacks for training.\n",
    "        time_grid (np.array, optional): Time grid for evaluation if required. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        model: Trained PyCox model.\n",
    "        logs: Training logs.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # Train the model\n",
    "    if config['model'] == 'deepsurv':\n",
    "        print('Initiate testing of deepsurv neural network')\n",
    "        X_test = df_event_focus(X_test, event_col, config['endpoint'])\n",
    "        if config['net'] == 'ann':\n",
    "            print('model structure: ANN')\n",
    "            X_test_processed, y_test = preprocess_data(X_test, config['features'], duration_col, event_col)\n",
    "            surv = model.predict_surv_df(X_test_processed, batch_size=512)\n",
    "        elif config['net'] == 'lstm':\n",
    "            print('model structure: LSTM')\n",
    "            X_test_processed, y_test = prepare_validation_data(X_test, config['features'], duration_col, event_col, config, cluster_col, config['model'], time_grid)\n",
    "            X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "            y_test_tensor = (torch.tensor(y_test[0], dtype=torch.float32), torch.tensor(y_test[1], dtype=torch.float32))\n",
    "            surv = model.predict_surv_df(X_test_tensor, batch_size=512)\n",
    "    elif config['model'] == 'deephit':\n",
    "        print('Initiate testing of deephit neural network')\n",
    "        if config['net'] == 'ann':\n",
    "            print('model structure: ANN')\n",
    "            X_test_processed, y_test = preprocess_data(X_test, config['features'], duration_col, event_col, time_grid, discretize=True)\n",
    "            surv = model.predict_cif(X_test_processed, batch_size=512)\n",
    "            print('prediction complete, please note that prediction of deephit models are CIF.')\n",
    "        elif config['net'] == 'lstm':\n",
    "            print('model structure: LSTM')\n",
    "            X_test_processed, y_test = prepare_validation_data(X_test, config['features'], duration_col, event_col, config, cluster_col, config['model'], time_grid)\n",
    "            surv = model.predict_cif(X_test_processed, batch_size=512)\n",
    "            print('prediction complete, please note that prediction of deephit models are CIF.')\n",
    "\n",
    "    # Free memory after training\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return surv, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_to_time_grid(surv, time_grid):\n",
    "    \"\"\"\n",
    "    Align the survival DataFrame to the closest indices of the time grid.\n",
    "\n",
    "    Parameters:\n",
    "        surv (pd.DataFrame): Survival probabilities DataFrame.\n",
    "        time_grid (np.array): Array of target time points to align.\n",
    "\n",
    "    Returns:\n",
    "        aligned_surv (pd.DataFrame): Aligned survival probabilities.\n",
    "    \"\"\"\n",
    "    # Convert the DataFrame's index to a NumPy array for fast computation\n",
    "    surv_times = np.array(surv.index)\n",
    "    \n",
    "    # Find the closest time in the survival DataFrame for each time in the grid\n",
    "    closest_indices = [np.argmin(np.abs(surv_times - t)) for t in time_grid]\n",
    "    \n",
    "    # Extract the rows corresponding to the closest times\n",
    "    aligned_surv = surv.iloc[closest_indices].copy()\n",
    "    \n",
    "    # Reindex the DataFrame to match the time grid\n",
    "    aligned_surv.index = range(len(time_grid))  # Standardize indices to 0, 1, 2, ...\n",
    "    return aligned_surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 00:59:25,848 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate testing of deepsurv neural network\n",
      "model structure: ANN\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m----> 2\u001b[0m surv, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeepsurv_ann_smoteenn_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepsurv_ann_smoteenn_1_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_transformed_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDURATION_COL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mevent_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEVENT_COL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLUSTER_COL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIME_GRID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m surv \u001b[38;5;241m=\u001b[39m align_to_time_grid(surv, TIME_GRID)\n\u001b[1;32m      5\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "Cell \u001b[0;32mIn[30], line 29\u001b[0m, in \u001b[0;36mpredict_neural_network\u001b[0;34m(model, config, X_test, duration_col, event_col, cluster_col, time_grid)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel structure: ANN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m     X_test_processed, y_test \u001b[38;5;241m=\u001b[39m preprocess_data(X_test, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], duration_col, event_col)\n\u001b[0;32m---> 29\u001b[0m     surv \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_surv_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel structure: LSTM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pycox/models/cox.py:154\u001b[0m, in \u001b[0;36m_CoxBase.predict_surv_df\u001b[0;34m(self, input, max_duration, batch_size, verbose, baseline_hazards_, eval_, num_workers)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_surv_df\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, max_duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8224\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, baseline_hazards_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m                     eval_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict survival function for `input`. S(x, t) = exp(-H(x, t))\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    Require computed baseline hazards.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m        pd.DataFrame -- Survival estimates. One columns for each individual.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_cumulative_hazards\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_hazards_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pycox/models/cox.py:129\u001b[0m, in \u001b[0;36m_CoxBase.predict_cumulative_hazards\u001b[0;34m(self, input, max_duration, batch_size, verbose, baseline_hazards_, eval_, num_workers)\u001b[0m\n\u001b[1;32m    126\u001b[0m     baseline_hazards_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline_hazards_\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m baseline_hazards_\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_monotonic_increasing,\\\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeed index of baseline_hazards_ to be monotonic increasing, as it represents time.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_cumulative_hazards\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_hazards_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43meval_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pycox/models/cox.py:252\u001b[0m, in \u001b[0;36m_CoxPHBase._predict_cumulative_hazards\u001b[0;34m(self, input, max_duration, batch_size, verbose, baseline_hazards_, eval_, num_workers)\u001b[0m\n\u001b[1;32m    250\u001b[0m bch \u001b[38;5;241m=\u001b[39m bch\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_duration]\n\u001b[1;32m    251\u001b[0m expg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28minput\u001b[39m, batch_size, \u001b[38;5;28;01mTrue\u001b[39;00m, eval_, num_workers\u001b[38;5;241m=\u001b[39mnum_workers))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mbch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpg\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m    253\u001b[0m                     index\u001b[38;5;241m=\u001b[39mbch\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "surv, y_test = predict_neural_network(model=loaded_models['deepsurv_ann_smoteenn_1'], config=deepsurv_ann_smoteenn_1_config, X_test=X_train_transformed_2, duration_col=DURATION_COL,\n",
    "                    event_col=EVENT_COL, cluster_col=CLUSTER_COL, time_grid=TIME_GRID)\n",
    "surv = align_to_time_grid(surv, TIME_GRID)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate testing of deephit neural network\n",
      "model structure: ANN\n",
      "prediction complete, please note that prediction of deephit models are CIF.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7593451986384061"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "surv, y_test = predict_neural_network(model=loaded_models['deephit_ann_nearmiss2_all'], config=deephit_ann_nearmiss2_all_config, X_test=X_train_transformed_2, duration_col=DURATION_COL,\n",
    "                    event_col=EVENT_COL, cluster_col=CLUSTER_COL, time_grid=TIME_GRID)\n",
    "surv1 = pd.DataFrame(surv[0], index=loaded_models['deephit_ann_nearmiss2_all'].duration_index)\n",
    "ev = EvalSurv(1- surv1, y_test[0], y_test[1] == 1, censor_surv='km')\n",
    "display(ev.concordance_td())\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 00:13:58,107 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating prediction for model: deepsurv_ann_clustering_1\n",
      "Initiate testing of deepsurv neural network\n",
      "model structure: ANN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 00:14:01,915 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed for deepsurv_ann_clustering_1.\n",
      "Initiating prediction for model: deepsurv_ann_smoteenn_1\n",
      "Initiate testing of deepsurv neural network\n",
      "model structure: ANN\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# model_ls = ['deepsurv_ann_clustering_1', 'deepsurv_ann_smoteenn_1', 'deepsurv_ann_smotetomek_1',\n",
    "#             'deepsurv_ann_clustering_2', 'deepsurv_ann_smoteenn_2', 'deepsurv_ann_smotetomek_2',\n",
    "#             'deepsurv_lstm_clustering_1', 'deepsurv_lstm_nearmiss', 'deepsurv_lstm_clustering_2', 'deepsurv_lstm_nearmiss_2',\n",
    "            # 'deephit_ann_clustering_all', 'deephit_ann_nearmiss2_all', 'deephit_lstm_clustering_all', 'deephit_lstm_nearmiss1_all'\n",
    "            # ]\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model_predictions = {}\n",
    "for model_name in model_ls:\n",
    "    # Retrieve configuration by dynamically constructing the variable name\n",
    "    config_var_name = model_name + \"_config\"\n",
    "    model_config = globals().get(config_var_name)\n",
    "    if model_config is None:\n",
    "        print(f\"Configuration for {config_var_name} not found.\")\n",
    "        continue\n",
    "    try:\n",
    "        print(f\"Initiating prediction for model: {model_name}\")\n",
    "        \n",
    "        # Retrieve the loaded model\n",
    "        model = loaded_models.get(model_name)\n",
    "        if model is None:\n",
    "            print(f\"Model {model_name} is not loaded.\")\n",
    "            continue\n",
    "        \n",
    "        # Predict using the loaded model and configuration\n",
    "        surv, y_test = predict_neural_network(\n",
    "            model=model,\n",
    "            config=model_config,\n",
    "            X_test=X_train_transformed_2,\n",
    "            duration_col=DURATION_COL,\n",
    "            event_col=EVENT_COL,\n",
    "            cluster_col=CLUSTER_COL,\n",
    "            time_grid=TIME_GRID\n",
    "        )\n",
    "        \n",
    "        if model_config['model'] == 'deepsurv':\n",
    "            surv = align_to_time_grid(surv, TIME_GRID).values  # 2D array\n",
    "            \n",
    "            # Structure key dynamically\n",
    "            key = f\"deepsurv_{model_config['net']}_{model_config['balance_method']}\"\n",
    "            \n",
    "            # Initialize if not exists\n",
    "            if key not in model_predictions:\n",
    "                model_predictions[key] = np.zeros((2, *surv.shape), dtype=np.float32)\n",
    "            \n",
    "            # Store predictions for the corresponding endpoint\n",
    "            if model_config['endpoint'] == 1:\n",
    "                model_predictions[key][0] = 1 - surv\n",
    "            elif model_config['endpoint'] == 2:\n",
    "                model_predictions[key][1] = 1 - surv\n",
    "        elif model_config['model'] == 'deephit':\n",
    "            surv = np.array(surv)  # Convert to numpy array\n",
    "            # Structure key dynamically\n",
    "            key = f\"deephit_{model_config['net']}_{model_config['balance_method']}\"\n",
    "            model_predictions[key] = surv\n",
    "        \n",
    "        print(f\"Prediction completed for {model_name}.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction for {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 40513)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6, 316242)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_predictions['deepsurv_lstm_clustering'][0].shape)\n",
    "display(model_predictions['deephit_lstm_clustering'][0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
