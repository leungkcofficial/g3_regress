{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:15:30,703 - INFO - Transforming training data...\n",
      "2024-11-03 23:15:46,784 - INFO - Transforming test data...\n"
     ]
    }
   ],
   "source": [
    "# Simplified and Best Practice Version of Import Statements\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import importlib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "\n",
    "# Pycox and PyTorch tuples for survival analysis\n",
    "import torchtuples as tt\n",
    "import pycox\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "from pycox.models import CoxPH, DeepHit\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "# Ray for hyperparameter tuning and distributed processing\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.air import session\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "# Custom modules for data handling, balancing, training, evaluation, and model architectures\n",
    "import dataloader2\n",
    "import databalancer2\n",
    "import datatrainer2\n",
    "import modeleval\n",
    "import netweaver2\n",
    "\n",
    "# Reload custom modules to ensure latest changes are available\n",
    "importlib.reload(dataloader2)\n",
    "importlib.reload(databalancer2)\n",
    "importlib.reload(datatrainer2)\n",
    "importlib.reload(modeleval)\n",
    "importlib.reload(netweaver2)\n",
    "\n",
    "# Import specific functions from custom modules to keep code clean and readable\n",
    "from netweaver2 import (\n",
    "    lstm_net_init, DHANNWrapper, LSTMWrapper, generalized_ann_net_init\n",
    ")\n",
    "from dataloader2 import (\n",
    "    load_and_transform_data, preprocess_data #stack_sequences, dh_dataset_loader\n",
    ")\n",
    "from databalancer2 import (\n",
    "    define_medoid_general, df_event_focus, rebalance_data, underbalance_data_general, medoid_cluster, \n",
    "    dh_rebalance_data\n",
    ")\n",
    "from datatrainer2 import (\n",
    "    recursive_clustering, prepare_training_data, \n",
    "    prepare_validation_data, lstm_training\n",
    ")\n",
    "from modeleval import (\n",
    "    dh_test_model, nam_dagostino_chi2, get_baseline_hazard_at_timepoints\n",
    ")\n",
    "\n",
    "import psutil\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Define Constants and Load Datasets\n",
    "RANDOM_SEED = 12345\n",
    "N_SPLIT = 10\n",
    "FEATURE_COLS = ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "DURATION_COL = 'date_from_sub_60'\n",
    "EVENT_COL = 'endpoint'\n",
    "CLUSTER_COL = 'key'\n",
    "TIME_GRID = np.array([i * 365 for i in range(6)])\n",
    "\n",
    "# Define Feature Groups\n",
    "CAT_FEATURES = ['gender', 'dm', 'ht', 'sprint']\n",
    "LOG_FEATURES = ['a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "STANDARD_FEATURES = ['age', 'alb', 'ca', 'hb', 'hco3']\n",
    "PASSTHROUGH_FEATURES = ['key', 'date_from_sub_60', 'endpoint']\n",
    "\n",
    "# Load and Transform Data\n",
    "BASE_FILENAME = '/mnt/d/pydatascience/g3_regress/data/X/X_20240628'\n",
    "X_train_transformed, X_test_transformed = load_and_transform_data(\n",
    "    BASE_FILENAME, CAT_FEATURES, LOG_FEATURES, STANDARD_FEATURES, PASSTHROUGH_FEATURES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(config):\n",
    "    \"\"\"\n",
    "    Function to create a neural network based on the given configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration dictionary containing model type, network type, and hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Created neural network model.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Create the Neural Network\n",
    "    if config['net'] == 'ann':\n",
    "        net = generalized_ann_net_init(\n",
    "            input_size=len(config['features']),\n",
    "            num_nodes=config[\"num_nodes\"],\n",
    "            batch_norm=config[\"batch_norm\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            output_size=1  # Default output size for DeepSurv\n",
    "        )\n",
    "    elif config['net'] == 'lstm':\n",
    "        net = lstm_net_init(\n",
    "            input_size=len(config['features']),\n",
    "            num_nodes=config[\"num_nodes\"],\n",
    "            batch_norm=config[\"batch_norm\"],\n",
    "            dropout=config[\"dropout\"]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown network type: {}\".format(config['net']))\n",
    "\n",
    "    optimizer = tt.optim.AdamWR(decoupled_weight_decay=1e-6, cycle_eta_multiplier=0.8)\n",
    "    if config['model'] == 'deepsurv':\n",
    "        model = CoxPH(net, optimizer)\n",
    "    elif config['model'] == 'deephit':\n",
    "        model = DeepHit(net, optimizer)\n",
    "    model.optimizer.set_lr(config[\"lr\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_neural_network(model, config, X_train, X_val, duration_col, event_col, cluster_col, callbacks, time_grid=None):\n",
    "    \"\"\"\n",
    "    Function to train a given neural network using the provided datasets.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): Neural network to be trained.\n",
    "        config (dict): Configuration dictionary containing model hyperparameters.\n",
    "        X_train (pd.DataFrame): Training dataset with features.\n",
    "        X_val (pd.DataFrame): Validation dataset with features.\n",
    "        duration_col (str): Column representing event durations.\n",
    "        event_col (str): Column representing event occurrences.\n",
    "        cluster_col (str): Column for grouping during cross-validation.\n",
    "        callbacks (list): List of callbacks for training.\n",
    "        time_grid (np.array, optional): Time grid for evaluation if required. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        model: Trained PyCox model.\n",
    "        logs: Training logs.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    # Prepare validation data (features and target labels)\n",
    "    X_val_processed, y_val = preprocess_data(X_val, config['features'], duration_col, event_col)\n",
    "    val_data = (X_val_processed, y_val)\n",
    "\n",
    "    # Train the model\n",
    "    if config['model'] == 'deepsurv':\n",
    "        if config['net'] == 'ann':\n",
    "            if config['balance_method'] == 'clustering':\n",
    "                model, logs = recursive_clustering(model, X_train, duration_col, event_col, config, val_data, callbacks, max_repeats=30)\n",
    "        elif config['net'] == 'lstm':\n",
    "            if config['balance_method'] == 'clustering':\n",
    "                model, logs = lstm_training(model, X_train, X_val, duration_col, event_col, cluster_col, config, callbacks, time_grid)\n",
    "\n",
    "    # Free memory after training\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'lstm',\n",
    "    'features': ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [8, 4],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.1144793446270997,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 9,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 3,\n",
    "}\n",
    "\n",
    "if config['net'] == 'ann':\n",
    "    net = generalized_ann_net_init(\n",
    "        input_size=len(config['features']),\n",
    "        num_nodes=config[\"num_nodes\"],\n",
    "        batch_norm=config[\"batch_norm\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        output_size=1  # Default output size for DeepSurv\n",
    "    )\n",
    "elif config['net'] == 'lstm':\n",
    "    net = lstm_net_init(\n",
    "        input_size=len(config['features']),\n",
    "        num_nodes=config[\"num_nodes\"],\n",
    "        batch_norm=config[\"batch_norm\"],\n",
    "        dropout=config[\"dropout\"]\n",
    "    )\n",
    "\n",
    "optimizer = tt.optim.AdamWR(decoupled_weight_decay=1e-6, cycle_eta_multiplier=0.8)\n",
    "model = CoxPH(net, optimizer)\n",
    "model.optimizer.set_lr(config[\"lr\"])\n",
    "callbacks = [tt.cb.EarlyStopping()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:45:58,875 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 23:45:58,882 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-03 23:45:58,883 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 23:45:58,887 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 23:45:59,630 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-03 23:45:59,631 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-03 23:45:59,632 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 23:45:59,635 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 23:46:00,119 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-03 23:46:00,120 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-03 23:46:00,120 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 23:46:00,124 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 23:46:03,043 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-03 23:46:03,044 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-03 23:46:03,045 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 23:46:03,049 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 23:46:03,490 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-03 23:46:03,492 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-03 23:46:03,493 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 23:46:03,497 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 23:46:03,927 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-03 23:46:03,929 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-03 23:46:03,929 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 23:46:03,932 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# prepare_training_data(df, feature_col, duration_col, event_col, params, cluster_col, clustering_method='define_medoid', time_grid=None)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDURATION_COL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEVENT_COL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLUSTER_COL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTIME_GRID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m prepare_validation_data(X_val_fold, feature_col, DURATION_COL, EVENT_COL, config, CLUSTER_COL, model_type, TIME_GRID)\n\u001b[1;32m      9\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/mnt/d/PYDataScience/g3_regress/code/datatrainer2.py:100\u001b[0m, in \u001b[0;36mprepare_training_data\u001b[0;34m(df, feature_col, duration_col, event_col, params, cluster_col, clustering_method, time_grid)\u001b[0m\n\u001b[1;32m     98\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming clustering iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepeat_count\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgoal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeepsurv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     X_cluster, remaining_data \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_medoid_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     X_cluster, remaining_data \u001b[38;5;241m=\u001b[39m define_medoid_general(df\u001b[38;5;241m=\u001b[39mremaining_data, feature_col\u001b[38;5;241m=\u001b[39mfeature_col, event_col\u001b[38;5;241m=\u001b[39mevent_col)\n",
      "File \u001b[0;32m/mnt/d/PYDataScience/g3_regress/code/databalancer2.py:118\u001b[0m, in \u001b[0;36mdefine_medoid_general\u001b[0;34m(df, feature_col, event_col, event_focus, n_neighbors, model_type)\u001b[0m\n\u001b[1;32m    116\u001b[0m nn \u001b[38;5;241m=\u001b[39m cuNN(n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    117\u001b[0m nn\u001b[38;5;241m.\u001b[39mfit(df_major_fea)\n\u001b[0;32m--> 118\u001b[0m distances, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_major_fea\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m total_distance \u001b[38;5;241m=\u001b[39m distances\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    120\u001b[0m cluster_center \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(total_distance)[:n_clusters]\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/cuml/internals/api_decorators.py:188\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     set_api_output_dtype(output_dtype)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_return:\n\u001b[0;32m--> 188\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/cuml/internals/api_decorators.py:393\u001b[0m, in \u001b[0;36menable_device_interop.<locals>.dispatch\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdispatch_func\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    392\u001b[0m     func_name \u001b[38;5;241m=\u001b[39m gpu_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gpu_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/cuml/internals/api_decorators.py:190\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cm\u001b[38;5;241m.\u001b[39mprocess_return(ret)\n",
      "File \u001b[0;32mbase.pyx:687\u001b[0m, in \u001b[0;36mcuml.internals.base.UniversalBase.dispatch_func\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnearest_neighbors.pyx:528\u001b[0m, in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors.kneighbors\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnearest_neighbors.pyx:621\u001b[0m, in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors._kneighbors_internal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbase.pyx:391\u001b[0m, in \u001b[0;36mcuml.internals.base.Base._get_output_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_dev/lib/python3.11/site-packages/cuml/__init__.py:120\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolvers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QN\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, __git_commit__\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_type = config['model']\n",
    "event_focus = config['endpoint']\n",
    "feature_col = config['features']\n",
    "\n",
    "gc.collect()\n",
    "# prepare_training_data(df, feature_col, duration_col, event_col, params, cluster_col, clustering_method='define_medoid', time_grid=None)\n",
    "X_train, y_train = prepare_training_data(X_train_transformed_3, feature_col, DURATION_COL, EVENT_COL, config, CLUSTER_COL, model_type, TIME_GRID)\n",
    "X_val, y_val = prepare_validation_data(X_val_fold, feature_col, DURATION_COL, EVENT_COL, config, CLUSTER_COL, model_type, TIME_GRID)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = (torch.tensor(y_train[0], dtype=torch.float32), torch.tensor(y_train[1], dtype=torch.float32))\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = (torch.tensor(y_val[0], dtype=torch.float32), torch.tensor(y_val[1], dtype=torch.float32))\n",
    "val_data = (X_val_tensor, y_val_tensor)\n",
    "\n",
    "dataset_size = X_train_tensor.size()[0]\n",
    "batch_size = min(config['batch_size'], dataset_size)\n",
    "# if dataset_size % batch_size == 1:\n",
    "#     batch_size = math.ceil(dataset_size / (math.floor(dataset_size / batch_size) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 00:04:27,580 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:27,583 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-04 00:04:27,584 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:27,586 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:28,231 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:28,232 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-04 00:04:28,233 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:28,237 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:28,685 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:28,686 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-04 00:04:28,687 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:28,691 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:29,134 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:29,136 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-04 00:04:29,136 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:29,140 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:29,581 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:29,582 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-04 00:04:29,583 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:29,586 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:30,014 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:30,016 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-04 00:04:30,017 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:30,020 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:30,478 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:30,479 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-04 00:04:30,480 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:30,485 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:30,932 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:30,934 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-04 00:04:30,934 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:30,938 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:31,389 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:31,390 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-04 00:04:31,391 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:31,395 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:31,838 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:31,839 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-04 00:04:31,840 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:31,844 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:32,308 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:32,309 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-04 00:04:32,309 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:32,314 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:32,770 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:32,772 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-04 00:04:32,772 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:32,777 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:33,201 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:33,203 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-04 00:04:33,204 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:33,208 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:36,117 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:36,118 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-04 00:04:36,119 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:36,123 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:36,528 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:36,529 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-04 00:04:36,530 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:36,533 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:36,926 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:36,928 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-04 00:04:36,928 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:36,933 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:37,325 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:37,326 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-04 00:04:37,327 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:37,330 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:37,727 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:37,729 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-04 00:04:37,729 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:37,733 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:38,120 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:38,121 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-04 00:04:38,121 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:38,125 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:38,502 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:38,504 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-04 00:04:38,505 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-04 00:04:38,508 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:04:38,886 - INFO - Defined medoid for deepsurv model with 1207 clusters.\n",
      "2024-11-04 00:04:38,900 - INFO - Cluster data retrieved\n",
      "2024-11-04 00:05:33,867 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-04 00:06:20,852 - INFO - Validation data retrieved\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.1756,\tval_loss: 5.9737\n",
      "1:\t[0s / 1s],\t\ttrain_loss: 2.4935,\tval_loss: 5.4709\n",
      "2:\t[0s / 2s],\t\ttrain_loss: 2.3906,\tval_loss: 5.6250\n",
      "3:\t[0s / 3s],\t\ttrain_loss: 2.3369,\tval_loss: 5.4939\n",
      "4:\t[0s / 3s],\t\ttrain_loss: 2.2701,\tval_loss: 5.5683\n",
      "5:\t[0s / 4s],\t\ttrain_loss: 2.2454,\tval_loss: 5.4326\n",
      "6:\t[0s / 5s],\t\ttrain_loss: 2.2264,\tval_loss: 5.3574\n",
      "7:\t[0s / 5s],\t\ttrain_loss: 2.3140,\tval_loss: 5.2434\n",
      "8:\t[0s / 6s],\t\ttrain_loss: 2.2340,\tval_loss: 5.4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "config = {\n",
    "    'model': 'deepsurv',\n",
    "    'net': 'lstm',\n",
    "    'balance_method': 'clustering',\n",
    "    'features': ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3'],\n",
    "    'endpoint': 1,\n",
    "    'num_nodes': [8, 4],\n",
    "    'batch_norm': False,\n",
    "    'dropout': 0.1144793446270997,\n",
    "    'lr': 0.1,\n",
    "    'max_epochs': 9,\n",
    "    'batch_size': 512,\n",
    "    'sampling_strategy': 0.05,\n",
    "    'seq_length': 3,\n",
    "}\n",
    "# Split final validation (fin_val) data for meta-learner\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "for train_idx_1, fin_val_idx in gss1.split(X=X_train_transformed[FEATURE_COLS], y=X_train_transformed[EVENT_COL], groups=X_train_transformed[CLUSTER_COL]):\n",
    "    X_train_transformed_2, X_fin_val = X_train_transformed.iloc[train_idx_1, :], X_train_transformed.iloc[fin_val_idx, :]\n",
    "    gc.collect()\n",
    "    \n",
    "    gss2 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    test_results = []\n",
    "    brier_df = pd.DataFrame()\n",
    "    for train_idx, val_idx in gss2.split(X=X_train_transformed_2[FEATURE_COLS], y=X_train_transformed_2[EVENT_COL], groups=X_train_transformed_2[CLUSTER_COL]):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        callbacks = [tt.cb.EarlyStopping()]\n",
    "        \n",
    "        X_train_transformed_3 = X_train_transformed_2.iloc[train_idx]\n",
    "        X_val_fold = X_train_transformed_2.iloc[val_idx]\n",
    "        X_val, y_val = preprocess_data(X_val_fold, config['features'], DURATION_COL, EVENT_COL)\n",
    "        val = (X_val, y_val)\n",
    "\n",
    "        model = create_neural_network(config)\n",
    "    \n",
    "        # model, logs = recursive_clustering(model, X_train_transformed_3, DURATION_COL, EVENT_COL, config, val, callbacks, max_repeats=30)\n",
    "        # model, logs = lstm_training(model, X_train_transformed_3, X_val_fold, DURATION_COL, EVENT_COL, CLUSTER_COL, config, callbacks, TIME_GRID)\n",
    "        model, logs = train_neural_network(model, config, X_train=X_train_transformed_3, X_val=X_val_fold, duration_col=DURATION_COL,\n",
    "                                                    event_col=EVENT_COL, cluster_col=CLUSTER_COL, callbacks=callbacks, time_grid=TIME_GRID)\n",
    "\n",
    "del model, logs\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_clustering(model, X_train_transformed, config['endpoint'], DURATION_COL, EVENT_COL, config['features'], config, val, callbacks, max_repeats=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:00:55,359 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 15:00:56,217 - INFO - Performing clustering iteration 1 / 20\n",
      "2024-11-03 15:00:56,217 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:00:56,225 - INFO - Event column 'endpoint' updated with focus on event value 1.\n",
      "2024-11-03 15:00:57,441 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:00:57,622 - INFO - Performing clustering iteration 2 / 20\n",
      "2024-11-03 15:00:57,623 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:00:57,628 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28:\t[0s / 0s],\t\ttrain_loss: 5.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:00:58,552 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:00:58,774 - INFO - Performing clustering iteration 3 / 20\n",
      "2024-11-03 15:00:58,775 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:00:58,779 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29:\t[0s / 0s],\t\ttrain_loss: 4.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:00:59,712 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:00:59,896 - INFO - Performing clustering iteration 4 / 20\n",
      "2024-11-03 15:00:59,897 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:00:59,902 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\t[0s / 0s],\t\ttrain_loss: 4.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:00,804 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:00,993 - INFO - Performing clustering iteration 5 / 20\n",
      "2024-11-03 15:01:00,994 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:00,998 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31:\t[0s / 0s],\t\ttrain_loss: 4.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:01,954 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:02,176 - INFO - Performing clustering iteration 6 / 20\n",
      "2024-11-03 15:01:02,176 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:02,181 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32:\t[0s / 0s],\t\ttrain_loss: 4.9698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:03,060 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:03,248 - INFO - Performing clustering iteration 7 / 20\n",
      "2024-11-03 15:01:03,248 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:03,253 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33:\t[0s / 0s],\t\ttrain_loss: 4.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:04,152 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:04,349 - INFO - Performing clustering iteration 8 / 20\n",
      "2024-11-03 15:01:04,350 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:04,355 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34:\t[0s / 0s],\t\ttrain_loss: 4.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:05,217 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:05,432 - INFO - Performing clustering iteration 9 / 20\n",
      "2024-11-03 15:01:05,433 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:05,437 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35:\t[0s / 0s],\t\ttrain_loss: 4.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:06,318 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:06,503 - INFO - Performing clustering iteration 10 / 20\n",
      "2024-11-03 15:01:06,503 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:06,508 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36:\t[0s / 0s],\t\ttrain_loss: 4.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:07,362 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:07,596 - INFO - Performing clustering iteration 11 / 20\n",
      "2024-11-03 15:01:07,597 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:07,601 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37:\t[0s / 0s],\t\ttrain_loss: 5.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:08,525 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:08,711 - INFO - Performing clustering iteration 12 / 20\n",
      "2024-11-03 15:01:08,712 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:08,716 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38:\t[0s / 0s],\t\ttrain_loss: 4.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:09,560 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:09,755 - INFO - Performing clustering iteration 13 / 20\n",
      "2024-11-03 15:01:09,756 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:09,760 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39:\t[0s / 0s],\t\ttrain_loss: 4.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:10,621 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:10,827 - INFO - Performing clustering iteration 14 / 20\n",
      "2024-11-03 15:01:10,828 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:10,833 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40:\t[0s / 0s],\t\ttrain_loss: 5.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:11,696 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:11,907 - INFO - Performing clustering iteration 15 / 20\n",
      "2024-11-03 15:01:11,908 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:11,913 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41:\t[0s / 0s],\t\ttrain_loss: 5.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:12,760 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:12,940 - INFO - Performing clustering iteration 16 / 20\n",
      "2024-11-03 15:01:12,941 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:12,945 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42:\t[0s / 0s],\t\ttrain_loss: 5.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:13,761 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:13,987 - INFO - Performing clustering iteration 17 / 20\n",
      "2024-11-03 15:01:13,988 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:13,995 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43:\t[0s / 0s],\t\ttrain_loss: 5.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:14,836 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:15,048 - INFO - Performing clustering iteration 18 / 20\n",
      "2024-11-03 15:01:15,049 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:15,055 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44:\t[0s / 0s],\t\ttrain_loss: 5.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:15,887 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:16,120 - INFO - Performing clustering iteration 19 / 20\n",
      "2024-11-03 15:01:16,121 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:16,125 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45:\t[0s / 0s],\t\ttrain_loss: 5.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:16,958 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n",
      "2024-11-03 15:01:17,141 - INFO - Performing clustering iteration 20 / 20\n",
      "2024-11-03 15:01:17,142 - INFO - CUDA environment set up and GPU memory cleared.\n",
      "2024-11-03 15:01:17,147 - INFO - Event column 'endpoint' updated with focus on event value 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46:\t[0s / 0s],\t\ttrain_loss: 5.0698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 15:01:17,945 - INFO - Defined medoid for deepsurv model with 1925 clusters.\n",
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47:\t[0s / 0s],\t\ttrain_loss: 5.0389\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "repeat_count = 0\n",
    "logs = []\n",
    "model_type = config['model']\n",
    "event_focus = config['endpoint']\n",
    "feature_col = config['features']\n",
    "max_repeats = 30\n",
    "\n",
    "remaining_data = df_event_focus(df=X_train_transformed, event_col=EVENT_COL, event_focus=config['endpoint']) if model_type == 'deepsurv' else df.copy()\n",
    "df_minor = remaining_data[remaining_data[EVENT_COL] == event_focus].copy() if model_type == 'deepsurv' else remaining_data[remaining_data[EVENT_COL] != 0].copy()\n",
    "df_major = remaining_data[remaining_data[EVENT_COL] != event_focus].copy() if model_type == 'deepsurv' else remaining_data[remaining_data[EVENT_COL] == 0].copy()\n",
    "\n",
    "goal = round(len(df_major) / len(df_minor)) - 1 if max_repeats == -1 else round(1 / config['sampling_strategy'])\n",
    "\n",
    "while len(remaining_data) > 0 and repeat_count < goal:\n",
    "    logging.info(f\"Performing clustering iteration {repeat_count + 1} / {goal}\")\n",
    "    if model_type == 'deepsurv':\n",
    "        X_cluster, remaining_data = define_medoid_general(df=remaining_data, feature_col=feature_col, event_col=EVENT_COL)\n",
    "        X_train_cluster, y_train_cluster = preprocess_data(df=X_cluster, feature_col=feature_col, duration_col=DURATION_COL, event_col=EVENT_COL)\n",
    "    else:\n",
    "        X_cluster, remaining_data = define_medoid_general(df=remaining_data, feature_col=feature_col, event_col=EVENT_COL)\n",
    "        X_train_cluster, y_train_cluster = preprocess_data(X_cluster, feature_col, DURATION_COL, EVENT_COL, TIME_GRID, discretize=True)\n",
    "\n",
    "    log = model.fit(X_train_cluster, y_train_cluster, config['batch_size'], config['max_epochs'], callbacks, verbose=True)\n",
    "    logs.append(log)\n",
    "    gc.collect()\n",
    "\n",
    "    # Early stopping check\n",
    "    if callbacks and hasattr(callbacks[0], 'stopped_epoch') and callbacks[0].stopped_epoch > 0:\n",
    "        logging.info(f\"Early stopping at epoch {callbacks[0].stopped_epoch}\")\n",
    "        break\n",
    "\n",
    "    repeat_count += 1\n",
    "    \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>dm</th>\n",
       "      <th>ht</th>\n",
       "      <th>sprint</th>\n",
       "      <th>a1c</th>\n",
       "      <th>po4</th>\n",
       "      <th>UACR_mg_g</th>\n",
       "      <th>Cr</th>\n",
       "      <th>age</th>\n",
       "      <th>alb</th>\n",
       "      <th>ca</th>\n",
       "      <th>hb</th>\n",
       "      <th>hco3</th>\n",
       "      <th>key</th>\n",
       "      <th>date_from_sub_60</th>\n",
       "      <th>endpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126422</td>\n",
       "      <td>0.718803</td>\n",
       "      <td>0.917315</td>\n",
       "      <td>0.766480</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.350878</td>\n",
       "      <td>0.303458</td>\n",
       "      <td>0.309179</td>\n",
       "      <td>0.363289</td>\n",
       "      <td>2695029</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.781061</td>\n",
       "      <td>0.832484</td>\n",
       "      <td>0.726740</td>\n",
       "      <td>0.411112</td>\n",
       "      <td>0.578948</td>\n",
       "      <td>0.401560</td>\n",
       "      <td>0.502416</td>\n",
       "      <td>0.267687</td>\n",
       "      <td>4565409</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169871</td>\n",
       "      <td>0.668293</td>\n",
       "      <td>0.874092</td>\n",
       "      <td>0.651472</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.456141</td>\n",
       "      <td>0.339003</td>\n",
       "      <td>0.338165</td>\n",
       "      <td>0.191205</td>\n",
       "      <td>1655813</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239518</td>\n",
       "      <td>0.657125</td>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.634679</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.456141</td>\n",
       "      <td>0.412330</td>\n",
       "      <td>0.429952</td>\n",
       "      <td>0.305928</td>\n",
       "      <td>6052274</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.746326</td>\n",
       "      <td>0.840789</td>\n",
       "      <td>0.815412</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.412742</td>\n",
       "      <td>0.454107</td>\n",
       "      <td>0.344169</td>\n",
       "      <td>5608947</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>0.735924</td>\n",
       "      <td>0.891154</td>\n",
       "      <td>0.714247</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.473685</td>\n",
       "      <td>0.304223</td>\n",
       "      <td>0.400967</td>\n",
       "      <td>0.458892</td>\n",
       "      <td>1655764</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187555</td>\n",
       "      <td>0.631314</td>\n",
       "      <td>0.886437</td>\n",
       "      <td>0.622796</td>\n",
       "      <td>0.311112</td>\n",
       "      <td>0.385966</td>\n",
       "      <td>0.328057</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>0.363289</td>\n",
       "      <td>415799</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395884</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.726289</td>\n",
       "      <td>0.866884</td>\n",
       "      <td>0.713979</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.298044</td>\n",
       "      <td>0.338165</td>\n",
       "      <td>0.327184</td>\n",
       "      <td>4827892</td>\n",
       "      <td>586.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150980</td>\n",
       "      <td>0.687764</td>\n",
       "      <td>0.915196</td>\n",
       "      <td>0.626973</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.578948</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.415460</td>\n",
       "      <td>0.325048</td>\n",
       "      <td>1677979</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307643</td>\n",
       "      <td>0.596224</td>\n",
       "      <td>0.878442</td>\n",
       "      <td>0.666297</td>\n",
       "      <td>0.633334</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.449276</td>\n",
       "      <td>0.537285</td>\n",
       "      <td>60065</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1925 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   dm   ht sprint       a1c       po4  UACR_mg_g        Cr  \\\n",
       "501       1.0  1.0  1.0    0.0  0.126422  0.718803   0.917315  0.766480   \n",
       "724       1.0  1.0  1.0    0.0  0.151458  0.781061   0.832484  0.726740   \n",
       "1302      1.0  1.0  1.0    1.0  0.169871  0.668293   0.874092  0.651472   \n",
       "1306      0.0  1.0  0.0    0.0  0.239518  0.657125   0.876405  0.634679   \n",
       "1656      1.0  0.0  1.0    0.0  0.151458  0.746326   0.840789  0.815412   \n",
       "...       ...  ...  ...    ...       ...       ...        ...       ...   \n",
       "395678    1.0  1.0  1.0    1.0  0.246211  0.735924   0.891154  0.714247   \n",
       "395860    0.0  0.0  1.0    0.0  0.187555  0.631314   0.886437  0.622796   \n",
       "395884    0.0  0.0  1.0    0.0  0.161575  0.726289   0.866884  0.713979   \n",
       "396200    0.0  1.0  0.0    0.0  0.150980  0.687764   0.915196  0.626973   \n",
       "396396    1.0  1.0  0.0    0.0  0.307643  0.596224   0.878442  0.666297   \n",
       "\n",
       "             age       alb        ca        hb      hco3      key  \\\n",
       "501     0.688889  0.350878  0.303458  0.309179  0.363289  2695029   \n",
       "724     0.411112  0.578948  0.401560  0.502416  0.267687  4565409   \n",
       "1302    0.800000  0.456141  0.339003  0.338165  0.191205  1655813   \n",
       "1306    0.677778  0.456141  0.412330  0.429952  0.305928  6052274   \n",
       "1656    0.577778  0.421053  0.412742  0.454107  0.344169  5608947   \n",
       "...          ...       ...       ...       ...       ...      ...   \n",
       "395678  0.566667  0.473685  0.304223  0.400967  0.458892  1655764   \n",
       "395860  0.311112  0.385966  0.328057  0.483092  0.363289   415799   \n",
       "395884  0.677778  0.561404  0.298044  0.338165  0.327184  4827892   \n",
       "396200  0.466667  0.578948  0.374166  0.415460  0.325048  1677979   \n",
       "396396  0.633334  0.298246  0.361248  0.449276  0.537285    60065   \n",
       "\n",
       "        date_from_sub_60  endpoint  \n",
       "501                740.0         1  \n",
       "724               1764.0         1  \n",
       "1302               300.0         1  \n",
       "1306              1790.0         1  \n",
       "1656              1764.0         1  \n",
       "...                  ...       ...  \n",
       "395678             608.0         1  \n",
       "395860             482.0         1  \n",
       "395884             586.0         1  \n",
       "396200            1523.0         1  \n",
       "396396            1024.0         1  \n",
       "\n",
       "[1925 rows x 16 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_data[remaining_data[EVENT_COL] == event_focus].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_clustering(model, df, event_focus, duration_col, event_col, feature_col, params, val, callbacks, max_repeats, model_type='deepsurv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
